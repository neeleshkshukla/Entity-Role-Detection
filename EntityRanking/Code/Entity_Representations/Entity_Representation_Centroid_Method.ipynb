{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation \n",
    "\n",
    "1. Reads the entity word and context word stored in doc_entity_context_word.p dictionary\n",
    "\n",
    "Dictionary format\n",
    "\n",
    "Element of Dictionary [ doc_id: dictonary of roles]\n",
    "\n",
    "Key: Document names present in the corpus\n",
    "Values: Dictionary of roles present in specific directory\n",
    "\n",
    "Elements of Role Dictionary: \n",
    "Keys: Roles present in a specific doc\n",
    "Value: List of entities having that role\n",
    "\n",
    "Entity list itself is a list of words\n",
    "\n",
    "\n",
    "2. Reads the word vector of the words from trained word emdeddings\n",
    "3. Takes the centroid(average) of word vectors\n",
    "4. Stores back them in dictionary \n",
    "\n",
    "Dictionary format\n",
    "\n",
    "Element of Dictionary [ doc_id: dictonary of roles]\n",
    "\n",
    "Key: Document names present in the corpus\n",
    "Values: Dictionary of roles present in specific directory\n",
    "\n",
    "Elements of Role Dictionary: \n",
    "Keys: Roles present in a specific doc\n",
    "Value: List of entities having that role\n",
    "\n",
    "Entity in the Entity list is 300-d vector which is centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import gensim, logging\n",
    "from gensim.models import Word2Vec, Phrases, phrases, KeyedVectors\n",
    "import scipy, numpy\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output_folder = '../../Data/output'\n",
    "train_entity_rep_output_folder = 'EntityRep/train'\n",
    "test_entity_rep_output_folder = 'EntityRep/test'\n",
    "entity_context_word_file = 'doc_entity_context_word.p'\n",
    "entity_doc_level_context_word_file = 'doc_entity_doc_Level_context_word.p'\n",
    "\n",
    "doc_level = True\n",
    "sent_level = False\n",
    "\n",
    "\n",
    "word_emnbedding_pretrained_trained_on_corpus = '../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file\n",
    "\n",
    "if sent_level:\n",
    "    train_doc_role_entity_context_word_dict = pickle.load(open(os.path.join(data_output_folder, train_entity_rep_output_folder, entity_context_word_file), 'rb'))\n",
    "    test_doc_role_entity_context_word_dict = pickle.load(open(os.path.join(data_output_folder, test_entity_rep_output_folder, entity_context_word_file), 'rb'))\n",
    "\n",
    "if doc_level:\n",
    "    train_doc_role_entity_context_word_dict = pickle.load(open(os.path.join(data_output_folder, train_entity_rep_output_folder, entity_doc_level_context_word_file), 'rb'))\n",
    "    test_doc_role_entity_context_word_dict = pickle.load(open(os.path.join(data_output_folder, test_entity_rep_output_folder, entity_doc_level_context_word_file), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-11 04:22:59,637 : INFO : loading projection weights from ../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt\n",
      "2018-05-11 04:25:10,499 : INFO : loaded (408497, 300) matrix from ../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt\n"
     ]
    }
   ],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(word_emnbedding_pretrained_trained_on_corpus, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8915391432210585"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector = word_vectors.get_vector('Narendra')\n",
    "size = len(word_vector)\n",
    "#print(type(word_vector))\n",
    "word_vectors.distance('Jammu', 'Narendra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_doc_role_entity_centroid_dictionary(doc_role_entity_context_word_dict):\n",
    "    \n",
    "    doc_role_entity_context_word_centroid_dict = dict()\n",
    "    \n",
    "    for doc in doc_role_entity_context_word_dict.keys():\n",
    "        \n",
    "        tag_dict = doc_role_entity_context_word_dict[doc]\n",
    "        tag_centroid_dict = dict()\n",
    "        for tag in tag_dict.keys():\n",
    "            entity_list = tag_dict[tag]\n",
    "            entity_centroid_list = list()\n",
    "            for entity in entity_list:\n",
    "                num_of_words_in_entity = len(entity[1])\n",
    "                entity_centroid = numpy.zeros(size)\n",
    "                for word in entity[1]:\n",
    "                    try:\n",
    "                        entity_centroid = numpy.add(entity_centroid, word_vectors.get_vector(word))\n",
    "                    except KeyError:\n",
    "                        num_of_words_in_entity = num_of_words_in_entity - 1\n",
    "                        \n",
    "                entity_centroid = entity_centroid/num_of_words_in_entity\n",
    "                entity_centroid_list.append((entity[0],entity_centroid))\n",
    "            tag_centroid_dict[tag] = entity_centroid_list\n",
    "        doc_role_entity_context_word_centroid_dict[doc] = tag_centroid_dict\n",
    "        \n",
    "    return doc_role_entity_context_word_centroid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_role_entity_context_word_centroid_dict = build_doc_role_entity_centroid_dictionary(train_doc_role_entity_context_word_dict)\n",
    "test_doc_role_entity_context_word_centroid_dict = build_doc_role_entity_centroid_dictionary(test_doc_role_entity_context_word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sent_level:\n",
    "    pickle.dump(train_doc_role_entity_context_word_centroid_dict, open('../../Data/output/EntityRep/train/doc_role_entity_context_word_centroid.p', 'wb'))\n",
    "    pickle.dump(test_doc_role_entity_context_word_centroid_dict, open('../../Data/output/EntityRep/test/doc_role_entity_context_word_centroid.p', 'wb'))\n",
    "    \n",
    "if doc_level:\n",
    "    pickle.dump(train_doc_role_entity_context_word_centroid_dict, open('../../Data/output/EntityRep/train/doc_role_entity_doc_level_context_word_centroid.p', 'wb'))\n",
    "    pickle.dump(test_doc_role_entity_context_word_centroid_dict, open('../../Data/output/EntityRep/test/doc_role_entity_doc_level_context_word_centroid.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
