{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create word embedding from corpus by Pretrained News vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import gensim, logging, os\n",
    "from gensim.models import Word2Vec, Phrases, phrases, KeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk import tokenize\n",
    "import string\n",
    "from itertools import chain\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec.FAST_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_dir = '../../Data/input/train/content'\n",
    "\n",
    "class Corpus_Sentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname;\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                yield line.split()\n",
    "                \n",
    "sentences = Corpus_Sentences(content_dir) # a memory-friendly iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-02 23:15:34,584 : INFO : loading projection weights from ../../../word_embeddings/pretrained_word_embeddings/Word2Vec/Glove_Converted/glove_2_word2vec.6B.300d.txt\n",
      "2018-05-02 23:17:50,116 : INFO : loaded (400000, 300) matrix from ../../../word_embeddings/pretrained_word_embeddings/Word2Vec/Glove_Converted/glove_2_word2vec.6B.300d.txt\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained glove vectors\n",
    "glove_wv = KeyedVectors.load_word2vec_format('../../../word_embeddings/pretrained_word_embeddings/Word2Vec/Glove_Converted/glove_2_word2vec.6B.300d.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-02 23:17:50,566 : INFO : collecting all words and their counts\n",
      "2018-05-02 23:17:50,923 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-05-02 23:18:02,140 : INFO : collected 18738 word types from a corpus of 325293 raw words and 854 sentences\n",
      "2018-05-02 23:18:02,141 : INFO : Loading a fresh vocabulary\n",
      "2018-05-02 23:18:02,226 : INFO : min_count=1 retains 18738 unique words (100% of original 18738, drops 0)\n",
      "2018-05-02 23:18:02,227 : INFO : min_count=1 leaves 325293 word corpus (100% of original 325293, drops 0)\n",
      "2018-05-02 23:18:02,459 : INFO : deleting the raw counts dictionary of 18738 items\n",
      "2018-05-02 23:18:02,461 : INFO : sample=0.001 downsamples 39 most-common words\n",
      "2018-05-02 23:18:02,465 : INFO : downsampling leaves estimated 236501 word corpus (72.7% of prior 325293)\n",
      "2018-05-02 23:18:02,583 : INFO : estimated required memory for 18738 words and 300 dimensions: 54340200 bytes\n",
      "2018-05-02 23:18:02,584 : INFO : resetting layer weights\n",
      "2018-05-02 23:18:03,052 : INFO : collecting all words and their counts\n",
      "2018-05-02 23:18:03,053 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-05-02 23:18:03,282 : INFO : collected 400000 word types from a corpus of 400000 raw words and 1 sentences\n",
      "2018-05-02 23:18:03,285 : INFO : Updating model with new vocabulary\n",
      "2018-05-02 23:18:07,845 : INFO : New added 400000 unique words (50% of original 800000) and increased the count of 400000 pre-existing words (50% of original 800000)\n",
      "2018-05-02 23:18:11,564 : INFO : deleting the raw counts dictionary of 400000 items\n",
      "2018-05-02 23:18:11,578 : INFO : sample=0.001 downsamples 0 most-common words\n",
      "2018-05-02 23:18:11,580 : INFO : downsampling leaves estimated 800000 word corpus (200.0% of prior 400000)\n",
      "2018-05-02 23:18:12,427 : INFO : estimated required memory for 800000 words and 300 dimensions: 2320000000 bytes\n",
      "2018-05-02 23:18:12,428 : INFO : updating layer weights\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary from corpus and words from pretrauned vector\n",
    "\n",
    "model = Word2Vec(size=300, min_count=1, iter=10)\n",
    "model.build_vocab(sentences)\n",
    "training_examples_count = model.corpus_count\n",
    "# below line will make it 1, so saving it before\n",
    "model.build_vocab([list(glove_wv.vocab.keys())], update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if lockf=0.0 then pretrained word vectors will not be trained so keeping lockf=1.0\n",
    "# Update the weights from pretrained vectors\n",
    "\n",
    "model.intersect_word2vec_format(\"../../../word_embeddings/pretrained_word_embeddings/Word2Vec/Glove_Converted/glove_2_word2vec.6B.300d.txt\",binary=False, lockf=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.train(sentences, total_examples=training_examples_count, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.wv.save_word2vec_format('../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.bin')\n",
    "model.wv.save_word2vec_format('../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt', binary=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
