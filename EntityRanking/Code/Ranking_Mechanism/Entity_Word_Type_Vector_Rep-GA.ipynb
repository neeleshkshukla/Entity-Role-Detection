{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, Phrases, phrases, KeyedVectors\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_ranking_op_folder = '../../../Data/output/Entity_Ranking'\n",
    "type_rep_folder = 'TypeRep/type_word'\n",
    "type_vec_folder = 'TypeVectors'\n",
    "entity_rep_folder = 'EntityRep'\n",
    "entity_context_word_file = 'doc_entity_context_word.p'\n",
    "per_type_rep_file_name = 'per_tag_vec_dict.p'\n",
    "org_type_rep_file_name = 'org_tag_vec_dict.p'\n",
    "loc_type_rep_file_name = 'loc_tag_vec_dict.p'\n",
    "\n",
    "word_emnbedding_pretrained_trained_on_corpus = '../../../word_embeddings/trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt'\n",
    "\n",
    "entity_context_word_file = os.path.join(entity_ranking_op_folder, entity_rep_folder, entity_context_word_file)\n",
    "per_type_rep_file = os.path.join(entity_ranking_op_folder, type_rep_folder, type_vec_folder, per_type_rep_file_name)\n",
    "org_type_rep_file = os.path.join(entity_ranking_op_folder, type_rep_folder, type_vec_folder, org_type_rep_file_name)\n",
    "loc_type_rep_file = os.path.join(entity_ranking_op_folder, type_rep_folder, type_vec_folder, loc_type_rep_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = ['LOC_Event', 'LOC_Accused', 'LOC_Victim', 'LOC_Others', 'ORG_Accused', 'ORG_Victim', 'ORG_Others', 'PER_Victim', 'PER_Others', 'PER_Accused']\n",
    "per_tag_list = ['PER_Victim', 'PER_Others', 'PER_Accused']\n",
    "loc_tag_list = ['LOC_Event', 'LOC_Accused', 'LOC_Victim', 'LOC_Others']\n",
    "org_tag_list = ['ORG_Accused', 'ORG_Victim', 'ORG_Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_rep_context_word_file_dict = pickle.load(open(entity_context_word_file, 'rb'))\n",
    "per_type_rep_dict = pickle.load(open(per_type_rep_file, 'rb'))\n",
    "org_type_rep_dict = pickle.load(open(org_type_rep_file, 'rb'))\n",
    "loc_type_rep_dict = pickle.load(open(loc_type_rep_file, 'rb'))\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word_emnbedding_pretrained_trained_on_corpus, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = word_vectors.get_vector('Narendra')\n",
    "size = len(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_average(entity, role):\n",
    "    num_of_words_in_entity = len(entity)\n",
    "    num_of_words_in_role = 1\n",
    "    total_number_of_words = num_of_words_in_entity + num_of_words_in_role\n",
    "    \n",
    "    sum_of_entity_type_word_vec = np.zeros(size)\n",
    "    for word in entity:\n",
    "        word_vec = word_vectors.get_vector(word)\n",
    "        word_vec = word_vec/np.linalg.norm(word_vec)\n",
    "        sum_of_entity_type_word_vec = np.add(sum_of_entity_type_word_vec, word_vec)\n",
    "    role = role/np.linalg.norm(role)\n",
    "    sum_of_entity_type_word_vec = np.add(sum_of_entity_type_word_vec, role)\n",
    "    \n",
    "    dot_product = np.dot(sum_of_entity_type_word_vec, sum_of_entity_type_word_vec)\n",
    "    group_avg = float(dot_product - (total_number_of_words))/(total_number_of_words * (total_number_of_words - 1))\n",
    "    return group_avg    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC_Event 48.63088718510405 %\n",
      "LOC_Accused 35.273972602739725 %\n",
      "LOC_Victim 50.0 %\n",
      "LOC_Others 66.34920634920636 %\n",
      "ORG_Accused 55.3125 %\n",
      "ORG_Victim 50.0 %\n",
      "ORG_Others 81.11964873765093 %\n",
      "PER_Victim 54.26829268292683 %\n",
      "PER_Others 80.57210965435041 %\n",
      "PER_Accused 67.93103448275862 %\n"
     ]
    }
   ],
   "source": [
    "precision1 = dict()\n",
    "doc_count_for_tag = dict()\n",
    "\n",
    "for tag in tag_list:\n",
    "    doc_count_for_tag[tag] = 0\n",
    "    precision1[tag] = 0\n",
    "    \n",
    "\n",
    "# Precision at K\n",
    "K = 2\n",
    "count = 0\n",
    "for doc_id in entity_rep_context_word_file_dict:\n",
    "    #print(doc_id)\n",
    "    num_actual_entities_with_role = dict()\n",
    "    if count > 0:\n",
    "        break\n",
    "    per_entities = list()\n",
    "    loc_entities = list()\n",
    "    org_entities = list()\n",
    "    doc_role_dict = entity_rep_context_word_file_dict[doc_id]\n",
    "    for role in doc_role_dict.keys():\n",
    "        entities = doc_role_dict[role]\n",
    "        num_actual_entities_with_role[role] = len(entities)\n",
    "        if role in per_tag_list:\n",
    "            for entity in entities:\n",
    "                per_entities.append((entity, role))\n",
    "        if role in org_tag_list:\n",
    "            for entity in entities:\n",
    "                org_entities.append((entity, role))\n",
    "        if role in loc_tag_list:\n",
    "            for entity in entities:\n",
    "                loc_entities.append((entity, role))\n",
    "    \n",
    "    num_per_entity = len(per_entities)\n",
    "    num_org_entity = len(org_entities)\n",
    "    num_loc_entity = len(loc_entities)\n",
    "    \n",
    "    for role in per_tag_list:\n",
    "        role_vector = per_type_rep_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in per_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0], role_vector)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_per_entity)):\n",
    "                #print(len(retrivedResult))\n",
    "                #print(role)\n",
    "                #print(num_actual_entities_with_role)\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            if TP ==  num_actual_entities_with_role[role]:\n",
    "                precision1[role] = precision1[role] + 1\n",
    "            else:\n",
    "                precision1[role] = precision1[role] + float(TP)/min(K, num_per_entity)\n",
    "                \n",
    "    for role in loc_tag_list:\n",
    "        role_vector = loc_type_rep_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in loc_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0], role_vector)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_loc_entity)):\n",
    "                #print(len(retrivedResult))\n",
    "                #print(role)\n",
    "                #print(num_actual_entities_with_role)\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            if TP ==  num_actual_entities_with_role[role]:\n",
    "                precision1[role] = precision1[role] + 1\n",
    "            else:\n",
    "                precision1[role] = precision1[role] + float(TP)/min(K, num_loc_entity)\n",
    "                \n",
    "    for role in org_tag_list:\n",
    "        role_vector = org_type_rep_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in org_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0], role_vector)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_org_entity)):\n",
    "                \n",
    "                #print(len(retrivedResult))\n",
    "                #print(role)\n",
    "                #print(num_actual_entities_with_role)\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            if TP ==  num_actual_entities_with_role[role]:\n",
    "                precision1[role] = precision1[role] + 1\n",
    "            else:\n",
    "                precision1[role] = precision1[role] + float(TP)/min(K, num_org_entity)\n",
    "    #print(num_actual_entities_with_role)\n",
    "    #count = 1\n",
    "\n",
    "for tag in tag_list:\n",
    "    if doc_count_for_tag[tag] > 0:\n",
    "        print(tag, float(precision1[tag] * 100)/doc_count_for_tag[tag], '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abc', 2.31), ('abc', 2.21), ('abc', 1.48), ('abc', 1.21)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "data = [('abc', 1.21),('abc', 2.31),('abc', 1.48), ('abc',2.21)]\n",
    "data = sorted(data,key=itemgetter(1), reverse=True)\n",
    "data[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([1,2,3])\n",
    "cosine_distance(a,b)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
