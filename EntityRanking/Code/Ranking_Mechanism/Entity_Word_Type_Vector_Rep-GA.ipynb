{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code Tests following configuration:\n",
    "\n",
    "Entity Representation: Context words + Words in Entity\n",
    "\n",
    "Type Representation: Type representation learned on training corpus\n",
    "\n",
    "Ranking Score: Group Average\n",
    "\n",
    "Word Representation: Trained word vectors on corpus initialized with pretrained glove vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, logging\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, Phrases, phrases, KeyedVectors\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_ranking_op_folder = '../../Data/output'\n",
    "type_rep_folder = 'TypeRep/type_word/train'\n",
    "entity_rep_test_folder = 'EntityRep/test'\n",
    "entity_context_word_file = 'doc_entity_context_word.p'\n",
    "entity_doc_level_context_word_file = 'doc_entity_doc_level_context_word.p'\n",
    "type_rep_file_name = 'tag_vec_dict.p'\n",
    "\n",
    "doc_level = True\n",
    "sent_level = False\n",
    "\n",
    "word_emnbedding_pretrained_trained_on_corpus = '../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt'\n",
    "\n",
    "entity_context_word_file = os.path.join(entity_ranking_op_folder, entity_rep_test_folder, entity_context_word_file)\n",
    "entity_doc_level_context_word_file = os.path.join(entity_ranking_op_folder, entity_rep_test_folder, entity_doc_level_context_word_file)\n",
    "type_rep_file = os.path.join(entity_ranking_op_folder, type_rep_folder, type_rep_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = ['LOC_Event', 'LOC_Accused', 'LOC_Victim', 'LOC_Others', 'ORG_Accused', 'ORG_Victim', 'ORG_Others', 'PER_Victim', 'PER_Others', 'PER_Accused']\n",
    "per_tag_list = ['PER_Victim', 'PER_Others', 'PER_Accused']\n",
    "loc_tag_list = ['LOC_Event', 'LOC_Accused', 'LOC_Victim', 'LOC_Others']\n",
    "org_tag_list = ['ORG_Accused', 'ORG_Victim', 'ORG_Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-11 05:27:34,693 : INFO : loading projection weights from ../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt\n",
      "2018-05-11 05:29:33,097 : INFO : loaded (408497, 300) matrix from ../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt\n"
     ]
    }
   ],
   "source": [
    "if sent_level:\n",
    "    entity_rep_context_word_file_dict = pickle.load(open(entity_context_word_file, 'rb'))\n",
    "if doc_level:\n",
    "    entity_rep_context_word_file_dict = pickle.load(open(entity_doc_level_context_word_file, 'rb'))\n",
    "type_rep_dict = pickle.load(open(type_rep_file, 'rb'))\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word_emnbedding_pretrained_trained_on_corpus, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = word_vectors.get_vector('Narendra')\n",
    "size = len(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_average(entity, role):\n",
    "    num_of_words_in_entity = len(entity)\n",
    "    num_of_words_in_role = 1\n",
    "    total_number_of_words = num_of_words_in_entity + num_of_words_in_role\n",
    "    \n",
    "    sum_of_entity_type_word_vec = np.zeros(size)\n",
    "    for word in entity:\n",
    "        try:\n",
    "            word_vec = word_vectors.get_vector(word)\n",
    "            word_vec = word_vec/np.linalg.norm(word_vec)\n",
    "        except KeyError:\n",
    "            word_vec = np.zeros(size)\n",
    "            \n",
    "        sum_of_entity_type_word_vec = np.add(sum_of_entity_type_word_vec, word_vec)\n",
    "    \n",
    "    role = role/np.linalg.norm(role)\n",
    "    sum_of_entity_type_word_vec = np.add(sum_of_entity_type_word_vec, role)\n",
    "    \n",
    "    dot_product = np.dot(sum_of_entity_type_word_vec, sum_of_entity_type_word_vec)\n",
    "    group_avg = float(dot_product - (total_number_of_words))/(total_number_of_words * (total_number_of_words - 1))\n",
    "    return group_avg    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC_Event 44.17989417989418 %\n",
      "LOC_Accused 20.3125 %\n",
      "LOC_Victim 29.166666666666668 %\n",
      "LOC_Others 67.75 %\n",
      "ORG_Accused 48.62385321100918 %\n",
      "ORG_Victim 33.333333333333336 %\n",
      "ORG_Others 79.0 %\n",
      "PER_Victim 50.0 %\n",
      "PER_Others 80.9659090909091 %\n",
      "PER_Accused 55.55555555555556 %\n",
      "Average 50.8887712037368 %\n"
     ]
    }
   ],
   "source": [
    "precision1 = dict()\n",
    "doc_count_for_tag = dict()\n",
    "\n",
    "for tag in tag_list:\n",
    "    doc_count_for_tag[tag] = 0\n",
    "    precision1[tag] = 0\n",
    "    \n",
    "\n",
    "# Precision at K\n",
    "K = 2\n",
    "count = 0\n",
    "for doc_id in entity_rep_context_word_file_dict:\n",
    "    #print(doc_id)\n",
    "    num_actual_entities_with_role = dict()\n",
    "    if count > 0:\n",
    "        break\n",
    "    per_entities = list()\n",
    "    loc_entities = list()\n",
    "    org_entities = list()\n",
    "    doc_role_dict = entity_rep_context_word_file_dict[doc_id]\n",
    "    for role in doc_role_dict.keys():\n",
    "        entities = doc_role_dict[role]\n",
    "        num_actual_entities_with_role[role] = len(entities)\n",
    "        if role in per_tag_list:\n",
    "            for entity in entities:\n",
    "                per_entities.append((entity, role))\n",
    "        if role in org_tag_list:\n",
    "            for entity in entities:\n",
    "                org_entities.append((entity, role))\n",
    "        if role in loc_tag_list:\n",
    "            for entity in entities:\n",
    "                loc_entities.append((entity, role))\n",
    "    \n",
    "    num_per_entity = len(per_entities)\n",
    "    num_org_entity = len(org_entities)\n",
    "    num_loc_entity = len(loc_entities)\n",
    "    \n",
    "    for role in per_tag_list:\n",
    "        role_vector = type_rep_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in per_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0][1], role_vector)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_per_entity)):\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            #if TP ==  num_actual_entities_with_role[role]:\n",
    "                #precision1[role] = precision1[role] + 1\n",
    "            #else:\n",
    "            precision1[role] = precision1[role] + float(TP)/min(K, num_per_entity)\n",
    "                \n",
    "    for role in loc_tag_list:\n",
    "        role_vector = type_rep_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in loc_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0][1], role_vector)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_loc_entity)):\n",
    "                #print(len(retrivedResult))\n",
    "                #print(role)\n",
    "                #print(num_actual_entities_with_role)\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            #if TP ==  num_actual_entities_with_role[role]:\n",
    "                #precision1[role] = precision1[role] + 1\n",
    "            #else:\n",
    "            precision1[role] = precision1[role] + float(TP)/min(K, num_loc_entity)\n",
    "                \n",
    "    for role in org_tag_list:\n",
    "        role_vector = type_rep_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in org_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0][1], role_vector)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_org_entity)):\n",
    "                \n",
    "                #print(len(retrivedResult))\n",
    "                #print(role)\n",
    "                #print(num_actual_entities_with_role)\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            #if TP ==  num_actual_entities_with_role[role]:\n",
    "             #   precision1[role] = precision1[role] + 1\n",
    "            #else:\n",
    "            precision1[role] = precision1[role] + float(TP)/min(K, num_org_entity)\n",
    "    #print(num_actual_entities_with_role)\n",
    "    #count = 1\n",
    "\n",
    "avg_pre = 0\n",
    "for tag in tag_list:\n",
    "    if doc_count_for_tag[tag] > 0:\n",
    "        avg_pre = avg_pre + float(precision1[tag] * 100)/doc_count_for_tag[tag]\n",
    "        print(tag, float(precision1[tag] * 100)/doc_count_for_tag[tag], '%')\n",
    "print('Average', avg_pre/10, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
