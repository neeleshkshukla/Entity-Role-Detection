{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code Tests following configuration:\n",
    "\n",
    "Entity Representation: Centroid of Context words + Words in Entity\n",
    "\n",
    "Type Representation: Type representation learned on training corpus\n",
    "\n",
    "Ranking Score: Group Average\n",
    "\n",
    "Word Representation: Trained word vectors on corpus initialized with pretrained glove vector embeddings\n",
    "\n",
    "Note: Gives the same results as cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "from operator import itemgetter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_ranking_op_folder = '../../Data/output'\n",
    "type_rep_folder = 'TypeRep/type_word/train'\n",
    "entity_rep_test_folder = 'EntityRep/test'\n",
    "entity_rep_file_name = 'doc_role_entity_context_word_centroid.p' \n",
    "type_rep_file_name = 'tag_vec_dict.p'\n",
    "\n",
    "entity_rep_file = os.path.join(entity_ranking_op_folder, entity_rep_test_folder, entity_rep_file_name)\n",
    "type_rep_file = os.path.join(entity_ranking_op_folder, type_rep_folder, type_rep_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = ['LOC_Event', 'LOC_Accused', 'LOC_Victim', 'LOC_Others', 'ORG_Accused', 'ORG_Victim', 'ORG_Others', 'PER_Victim', 'PER_Others', 'PER_Accused']\n",
    "per_tag_list = ['PER_Victim', 'PER_Others', 'PER_Accused']\n",
    "loc_tag_list = ['LOC_Event', 'LOC_Accused', 'LOC_Victim', 'LOC_Others']\n",
    "org_tag_list = ['ORG_Accused', 'ORG_Victim', 'ORG_Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_rep_doc_role_context_dict = pickle.load(open(entity_rep_file, 'rb'))\n",
    "type_rep_dict = pickle.load(open(type_rep_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_average(entity, role):\n",
    "    \n",
    "    size = 300\n",
    "    num_of_words_in_entity = 1\n",
    "    num_of_words_in_role = 1\n",
    "    total_number_of_words = num_of_words_in_entity + num_of_words_in_role\n",
    "    \n",
    "    sum_of_entity_type_word_vec = np.zeros(size)\n",
    "    \n",
    "    entity = entity/np.linalg.norm(entity)\n",
    "    sum_of_entity_type_word_vec = np.add(sum_of_entity_type_word_vec, entity)\n",
    "        \n",
    "    role = role/np.linalg.norm(role)\n",
    "    sum_of_entity_type_word_vec = np.add(sum_of_entity_type_word_vec, role)\n",
    "    \n",
    "    dot_product = np.dot(sum_of_entity_type_word_vec, sum_of_entity_type_word_vec)\n",
    "    group_avg = float(dot_product - (total_number_of_words))/(total_number_of_words * (total_number_of_words - 1))\n",
    "    return group_avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC_Event 66.93121693121694 %\n",
      "LOC_Accused 29.6875 %\n",
      "LOC_Victim 20.833333333333332 %\n",
      "LOC_Others 61.0 %\n",
      "ORG_Accused 73.39449541284404 %\n",
      "ORG_Victim 53.333333333333336 %\n",
      "ORG_Others 80.75 %\n",
      "PER_Victim 57.8125 %\n",
      "PER_Others 84.6590909090909 %\n",
      "PER_Accused 53.17460317460318 %\n"
     ]
    }
   ],
   "source": [
    "precision1 = dict()\n",
    "doc_count_for_tag = dict()\n",
    "\n",
    "for tag in tag_list:\n",
    "    doc_count_for_tag[tag] = 0\n",
    "    precision1[tag] = 0\n",
    "    \n",
    "\n",
    "# Precision at K\n",
    "K = 2\n",
    "count = 0\n",
    "for doc_id in entity_rep_doc_role_context_dict:\n",
    "    #print(doc_id)\n",
    "    num_actual_entities_with_role = dict()\n",
    "    if count > 0:\n",
    "        break\n",
    "    per_entities = list()\n",
    "    loc_entities = list()\n",
    "    org_entities = list()\n",
    "    doc_role_dict = entity_rep_doc_role_context_dict[doc_id]\n",
    "    for role in doc_role_dict.keys():\n",
    "        entities = doc_role_dict[role]\n",
    "        num_actual_entities_with_role[role] = len(entities)\n",
    "        if role in per_tag_list:\n",
    "            for entity in entities:\n",
    "                per_entities.append((entity, role))\n",
    "        if role in org_tag_list:\n",
    "            for entity in entities:\n",
    "                org_entities.append((entity, role))\n",
    "        if role in loc_tag_list:\n",
    "            for entity in entities:\n",
    "                loc_entities.append((entity, role))\n",
    "    \n",
    "    num_per_entity = len(per_entities)\n",
    "    num_org_entity = len(org_entities)\n",
    "    num_loc_entity = len(loc_entities)\n",
    "    \n",
    "    for role in per_tag_list:\n",
    "        role_vector = type_rep_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in per_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0], role_vector)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_per_entity)):\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            if TP ==  num_actual_entities_with_role[role]:\n",
    "                precision1[role] = precision1[role] + 1\n",
    "            else:\n",
    "                precision1[role] = precision1[role] + float(TP)/min(K, num_per_entity)\n",
    "                \n",
    "    for role in loc_tag_list:\n",
    "        role_vector = type_rep_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in loc_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0], role_vector)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_loc_entity)):\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            if TP ==  num_actual_entities_with_role[role]:\n",
    "                precision1[role] = precision1[role] + 1\n",
    "            else:\n",
    "                precision1[role] = precision1[role] + float(TP)/min(K, num_loc_entity)\n",
    "                \n",
    "    for role in org_tag_list:\n",
    "        role_vector = type_rep_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in org_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0], role_vector)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_org_entity)):\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            if TP ==  num_actual_entities_with_role[role]:\n",
    "                precision1[role] = precision1[role] + 1\n",
    "            else:\n",
    "                precision1[role] = precision1[role] + float(TP)/min(K, num_org_entity)\n",
    "\n",
    "for tag in tag_list:\n",
    "    if doc_count_for_tag[tag] > 0:\n",
    "        print(tag, float(precision1[tag] * 100)/doc_count_for_tag[tag], '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abc', 2.31), ('abc', 2.21), ('abc', 1.48), ('abc', 1.21)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "data = [('abc', 1.21),('abc', 2.31),('abc', 1.48), ('abc',2.21)]\n",
    "data = sorted(data,key=itemgetter(1), reverse=True)\n",
    "data[0:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
