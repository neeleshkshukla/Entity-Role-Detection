{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code Tests following configuration:\n",
    "\n",
    "Entity Representation: Words in Entity and Context Words\n",
    "\n",
    "Type Representation: Similar words to type representation learned on training corpus\n",
    "\n",
    "Ranking Score: Group Average\n",
    "\n",
    "Word Representation: Trained word vectors on corpus initialized with pretrained glove vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, logging, pickle\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, Phrases, phrases, KeyedVectors\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_ranking_op_folder = '../../Data/output'\n",
    "type_rep_folder = 'TypeRep/type_word/train'\n",
    "entity_rep_test_folder = 'EntityRep/test'\n",
    "entity_context_word_file = 'doc_entity_context_word.p'\n",
    "type_word_file_name = 'tag_word_dict.p'\n",
    "\n",
    "word_emnbedding_pretrained_trained_on_corpus = '../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt'\n",
    "\n",
    "entity_context_word_file = os.path.join(entity_ranking_op_folder, entity_rep_test_folder, entity_context_word_file)\n",
    "type_word_file = os.path.join(entity_ranking_op_folder, type_rep_folder, type_word_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = ['LOC_Event', 'LOC_Accused', 'LOC_Victim', 'LOC_Others', 'ORG_Accused', 'ORG_Victim', 'ORG_Others', 'PER_Victim', 'PER_Others', 'PER_Accused']\n",
    "per_tag_list = ['PER_Victim', 'PER_Others', 'PER_Accused']\n",
    "loc_tag_list = ['LOC_Event', 'LOC_Accused', 'LOC_Victim', 'LOC_Others']\n",
    "org_tag_list = ['ORG_Accused', 'ORG_Victim', 'ORG_Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC_Event [('Udgir', 0.7491601705551147), ('Hyderabad', 0.7469158172607422), ('Masjid', 0.7268767356872559), ('December', 0.7225533723831177), ('October', 0.7208514213562012), ('West', 0.7201897501945496), ('Ajmer', 0.7032129764556885), ('Assam', 0.6985844373703003), ('Bengal', 0.6918336153030396), ('February', 0.6780576705932617), ('September', 0.6680309772491455), ('blasts', 0.6621419191360474), ('North', 0.6534678936004639), ('the', 0.6438105702400208), ('three', 0.6426020860671997), ('al-Sadr', 0.6417630910873413), ('bomb', 0.640689492225647), ('RSS', 0.6375901103019714), ('Varanasi', 0.6354883313179016), ('Ahmedabad', 0.6352523565292358), ('Caf', 0.6344596147537231), ('district', 0.6304529905319214), ('2007', 0.622878909111023), ('Kashmir', 0.6182977557182312), ('House', 0.6181615591049194), ('Orissa', 0.6146178245544434), ('blast', 0.6135209202766418), ('Bihar', 0.6130719780921936), ('Baghdad', 0.6105132102966309), ('Peshawar', 0.6065664291381836)] \n",
      "\n",
      "LOC_Accused [('terrorist', 0.6620270013809204), ('if', 0.6429504156112671), ('terror', 0.6149424314498901), ('become', 0.5985813140869141), ('organisation', 0.5980174541473389), ('Hizbul', 0.5925683975219727), ('Nokia', 0.5821705460548401), ('most', 0.5727019906044006), ('Rs', 0.5622836351394653), ('Rao', 0.5598036050796509), ('Swayamsevak', 0.5546649694442749), ('militant', 0.5538785457611084), ('or', 0.5514105558395386), ('radical', 0.5469186305999756), ('has', 0.5434588193893433), ('PETN', 0.5414755344390869), ('being', 0.540607750415802), ('group', 0.539267897605896), ('Syed', 0.5379534959793091), ('Rashtriya', 0.5347431898117065), ('kind', 0.5335004925727844), ('Six', 0.5329839587211609), ('Jali', 0.5308460593223572), ('active', 0.5290777087211609), ('what', 0.5283163785934448), ('political', 0.5273203253746033), ('any', 0.5210027694702148), ('organization', 0.5202843546867371), ('within', 0.5199722647666931), ('Ten', 0.5192840695381165)] \n",
      "\n",
      "LOC_Victim [('bharatpur', 0.2510189414024353), ('chalukya', 0.24209651350975037), ('onwards', 0.2409936487674713), ('1417', 0.23848706483840942), ('mists', 0.23650053143501282), ('sloop-of-war', 0.2351970672607422), ('mid-september', 0.23039427399635315), ('mid-20th', 0.23014235496520996), ('pallavas', 0.2286701649427414), ('mid-15th', 0.2271554321050644), ('121.74', 0.22679123282432556), ('seventies', 0.22562041878700256), ('stukas', 0.22477640211582184), ('soil-borne', 0.22397461533546448), ('mid-1950s', 0.2234472781419754), ('1191', 0.2233913093805313), ('chittorgarh', 0.22331514954566956), ('1414', 0.2226627618074417), ('1870s', 0.22208274900913239), ('downton', 0.22102484107017517), ('1798', 0.22026404738426208), ('Khaleelur', 0.22023238241672516), ('tongeren', 0.2192142903804779), ('greystones', 0.21890951693058014), ('dobruja', 0.2186652570962906), ('multi-drug', 0.21862024068832397), ('seljuk', 0.2181374728679657), ('1418', 0.21690422296524048), ('pre-colonial', 0.21668817102909088), ('vulcan', 0.21636544167995453)] \n",
      "\n",
      "LOC_Others [('The', 0.9052245020866394), ('OPEN', 0.8425198793411255), ('the', 0.8340882658958435), ('Special', 0.8259127140045166), (',', 0.824306309223175), ('on', 0.7958601713180542), ('.', 0.7936317920684814), (\"'s\", 0.7845897078514099), ('in', 0.7833923101425171), ('two', 0.7753007411956787), ('Baig', 0.7700053453445435), ('from', 0.76596599817276), ('case', 0.7652240991592407), ('a', 0.7644075751304626), ('was', 0.764361560344696), ('also', 0.7617778182029724), ('to', 0.7598540782928467), ('them', 0.7596411108970642), ('of', 0.7550713419914246), ('and', 0.7550250291824341), ('is', 0.7547339797019958), ('several', 0.7507610321044922), ('people', 0.7493109107017517), ('had', 0.7489567399024963), ('A', 0.746884286403656), ('that', 0.745251476764679), ('an', 0.743687629699707), ('Police', 0.7411222457885742), ('as', 0.7405234575271606), ('it', 0.7385463714599609)] \n",
      "\n",
      "ORG_Accused [('Act', 0.6397272348403931), ('ATS', 0.6334722638130188), ('banned', 0.6142570972442627), ('or', 0.6118773221969604), ('Code', 0.6098564267158508), ('Penal', 0.6096556782722473), ('terror', 0.6035995483398438), ('Sri', 0.6014197468757629), ('Viqaruddin', 0.599727988243103), ('Indian', 0.5967807769775391), ('terrorist', 0.5899637937545776), ('High', 0.5897033214569092), ('Unlawful', 0.5887771844863892), ('accused', 0.5878908634185791), ('Squad', 0.5678592920303345), ('alleged', 0.560774564743042), ('terrorism', 0.5607564449310303), ('is', 0.5572926998138428), ('has', 0.5545469522476196), ('Swami', 0.5538744330406189), ('charge', 0.5534637570381165), ('activities', 0.5523183345794678), ('Abhinav', 0.5444592833518982), ('involvement', 0.5434684157371521), ('RSS', 0.5421695709228516), ('charge-sheets', 0.5416449904441833), ('Explosives', 0.5364795923233032), ('suspected', 0.530892014503479), ('Bharat', 0.5281825065612793), ('convenership', 0.5250141620635986)] \n",
      "\n",
      "ORG_Victim [('Muslim', 0.787793755531311), ('charge-sheet', 0.7281893491744995), ('Christian', 0.7006553411483765), ('Act', 0.6929014921188354), ('Explosives', 0.6588337421417236), ('Centre', 0.6583470106124878), ('Unlawful', 0.654787540435791), ('Siddique', 0.6474324464797974), ('Immadoddin', 0.6329662799835205), ('Besides', 0.6302651166915894), ('Harekrushna', 0.6280699968338013), ('convenership', 0.6137670874595642), ('Chowdhary', 0.6057511568069458), ('SIM', 0.598790168762207), ('Lashkar-e-Taiba', 0.5970743894577026), ('Writing', 0.5961843729019165), ('Behera', 0.5941300392150879), ('Sahpur-Patori', 0.5921137928962708), ('DSP', 0.5904253721237183), ('Lima', 0.5878912210464478), ('building', 0.5848491787910461), ('Makkah', 0.5841468572616577), ('Nagaland', 0.5808297395706177), ('Swami', 0.5755252838134766), ('Abubucker', 0.5691443681716919), ('Additional', 0.5691152811050415), ('Under', 0.5622432231903076), ('blasts', 0.5608084797859192), ('Sabha', 0.5605928301811218), ('Only', 0.5580249428749084)] \n",
      "\n",
      "ORG_Others [('The', 0.8931543231010437), ('the', 0.82491534948349), (',', 0.8167579174041748), ('OPEN', 0.8090630769729614), ('also', 0.8066927790641785), (')', 0.7996429204940796), ('Additional', 0.7927863001823425), ('has', 0.7901641130447388), ('Special', 0.769687294960022), ('and', 0.7664356827735901), ('is', 0.7658307552337646), ('who', 0.7634927034378052), ('was', 0.762890100479126), ('of', 0.7627683877944946), ('that', 0.7618882656097412), ('(', 0.761608362197876), ('.', 0.7533376216888428), ('said', 0.749068021774292), ('Justice', 0.7461720705032349), ('had', 0.7454918026924133), ('Baig', 0.7451053857803345), ('Pradesh', 0.7322139739990234), ('for', 0.7312124371528625), ('charge', 0.7266024947166443), ('Mr.', 0.7255681753158569), ('Joshi', 0.7233060598373413), ('case', 0.718872606754303), ('from', 0.718636155128479), ('Mohanty', 0.7180936336517334), ('been', 0.7133886218070984)] \n",
      "\n",
      "PER_Victim [('District', 0.7561756372451782), ('Bench', 0.7547467947006226), ('Mohammed', 0.747001051902771), ('Gupta', 0.7295229434967041), ('Personnel', 0.7236689329147339), ('One', 0.7136021852493286), ('Viqar', 0.7011110782623291), ('Shabari', 0.6999355554580688), ('Joshi', 0.6996506452560425), ('A', 0.6850175857543945), ('Supporters', 0.6839958429336548), ('Anita', 0.6814148426055908), ('Sub-Divisional', 0.6796690225601196), ('Pongal', 0.6767937541007996), ('killing', 0.6672681570053101), ('B.', 0.6625639200210571), ('Bihar', 0.6599655151367188), ('Police', 0.6590099930763245), ('them', 0.6541696786880493), ('Sessions', 0.653090238571167), ('Squad', 0.6501339673995972), ('Incidents', 0.6485193967819214), ('SIM', 0.6437301635742188), ('Yasin', 0.6426377892494202), ('Railway', 0.6425950527191162), ('Saif', 0.6423922777175903), ('The', 0.6406450867652893), ('Page', 0.6389589309692383), ('In', 0.6384420394897461), ('Lokesh', 0.6363815665245056)] \n",
      "\n",
      "PER_Others [('The', 0.850013792514801), ('Mr.', 0.8265564441680908), (',', 0.8201037645339966), ('said', 0.8159671425819397), ('that', 0.7958603501319885), ('told', 0.7812865972518921), ('the', 0.7805700302124023), ('Minister', 0.7803834676742554), ('Additional', 0.7790704965591431), ('OPEN', 0.7777080535888672), ('also', 0.7775581479072571), (\"'s\", 0.7707945108413696), ('Rajasthan', 0.7684800028800964), ('Baig', 0.7657429575920105), ('Bihar', 0.7653252482414246), ('Chief', 0.7502701282501221), ('police', 0.7441765666007996), ('saying', 0.7404714226722717), ('.', 0.7373757362365723), ('as', 0.7373486757278442), ('was', 0.730509340763092), ('Police', 0.7303580641746521), ('ATS', 0.7279449701309204), ('Hindu', 0.7247112989425659), ('CBI', 0.719517707824707), ('asked', 0.7160272598266602), ('who', 0.7132338285446167), ('Special', 0.7125692367553711), ('says', 0.7117091417312622), ('while', 0.7087891101837158)] \n",
      "\n",
      "PER_Accused [('The', 0.8391270637512207), ('who', 0.8365209102630615), ('the', 0.783484697341919), (',', 0.7766008377075195), ('also', 0.7721375823020935), ('Justice', 0.7696315050125122), ('Police', 0.7681658864021301), ('OPEN', 0.7602031230926514), ('them', 0.7585505843162537), ('from', 0.7397404909133911), ('police', 0.7373321652412415), ('ATS', 0.7372124195098877), ('case', 0.7357320785522461), ('Maharashtra', 0.7357212901115417), ('Mr.', 0.7326108813285828), ('charge', 0.7319756746292114), ('SIM', 0.7267596125602722), ('to', 0.7248544692993164), ('and', 0.7235709428787231), ('Rajasthan', 0.7220888137817383), ('for', 0.7219545841217041), ('reportedly', 0.7143980264663696), ('has', 0.714147686958313), ('was', 0.7130297422409058), ('Pradesh', 0.7127139568328857), ('been', 0.712435781955719), ('accused', 0.7108049988746643), ('his', 0.7105393409729004), ('others', 0.7087645530700684), ('him', 0.7085418701171875)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "entity_rep_context_word_file_dict = pickle.load(open(entity_context_word_file, 'rb'))\n",
    "type_word_dict = pickle.load(open(type_word_file, 'rb'))\n",
    "for tag in tag_list:\n",
    "    print(tag, type_word_dict[tag], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-03 06:03:14,647 : INFO : loading projection weights from ../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt\n",
      "2018-05-03 06:05:30,943 : INFO : loaded (408497, 300) matrix from ../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt\n"
     ]
    }
   ],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(word_emnbedding_pretrained_trained_on_corpus, binary=False)\n",
    "word_vector = word_vectors.get_vector('Narendra')\n",
    "size = len(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_average(entity, role_tuple):\n",
    "    num_of_words_in_entity = len(entity)\n",
    "    num_of_words_in_role = len(role)\n",
    "    total_number_of_words = num_of_words_in_entity + num_of_words_in_role\n",
    "    \n",
    "    sum_of_entity_type_word_vec = np.zeros(size)\n",
    "    for word in entity:\n",
    "        try:\n",
    "            word_vec = word_vectors.get_vector(word)\n",
    "            word_vec = word_vec/np.linalg.norm(word_vec)\n",
    "        except KeyError:\n",
    "            word_vec = np.zeros(size)\n",
    "            \n",
    "        sum_of_entity_type_word_vec = np.add(sum_of_entity_type_word_vec, word_vec)\n",
    "    \n",
    "    for tup in role_tuple:\n",
    "        try:\n",
    "            word_vec = word_vectors.get_vector(tup[0])\n",
    "            word_vec = word_vec/np.linalg.norm(word_vec)\n",
    "        except KeyError:\n",
    "            word_vec = np.zeros(size)\n",
    "        \n",
    "        sum_of_entity_type_word_vec = np.add(sum_of_entity_type_word_vec, word_vec)\n",
    "        \n",
    "    dot_product = np.dot(sum_of_entity_type_word_vec, sum_of_entity_type_word_vec)\n",
    "    group_avg = float(dot_product - (total_number_of_words))/(total_number_of_words * (total_number_of_words - 1))\n",
    "    return group_avg    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC_Event 50.264550264550266 %\n",
      "LOC_Accused 9.375 %\n",
      "LOC_Victim 33.333333333333336 %\n",
      "LOC_Others 66.0 %\n",
      "ORG_Accused 61.46788990825688 %\n",
      "ORG_Victim 33.333333333333336 %\n",
      "ORG_Others 78.0 %\n",
      "PER_Victim 50.0 %\n",
      "PER_Others 86.36363636363636 %\n",
      "PER_Accused 47.61904761904762 %\n"
     ]
    }
   ],
   "source": [
    "precision1 = dict()\n",
    "doc_count_for_tag = dict()\n",
    "\n",
    "for tag in tag_list:\n",
    "    doc_count_for_tag[tag] = 0\n",
    "    precision1[tag] = 0\n",
    "    \n",
    "\n",
    "# Precision at K\n",
    "K = 1\n",
    "count = 0\n",
    "for doc_id in entity_rep_context_word_file_dict:\n",
    "    #print(doc_id)\n",
    "    num_actual_entities_with_role = dict()\n",
    "    if count > 0:\n",
    "        break\n",
    "    per_entities = list()\n",
    "    loc_entities = list()\n",
    "    org_entities = list()\n",
    "    doc_role_dict = entity_rep_context_word_file_dict[doc_id]\n",
    "    for role in doc_role_dict.keys():\n",
    "        entities = doc_role_dict[role]\n",
    "        num_actual_entities_with_role[role] = len(entities)\n",
    "        if role in per_tag_list:\n",
    "            for entity in entities:\n",
    "                per_entities.append((entity, role))\n",
    "        if role in org_tag_list:\n",
    "            for entity in entities:\n",
    "                org_entities.append((entity, role))\n",
    "        if role in loc_tag_list:\n",
    "            for entity in entities:\n",
    "                loc_entities.append((entity, role))\n",
    "    \n",
    "    num_per_entity = len(per_entities)\n",
    "    num_org_entity = len(org_entities)\n",
    "    num_loc_entity = len(loc_entities)\n",
    "    \n",
    "    for role in per_tag_list:\n",
    "        role_word = type_word_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in per_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0], role_word)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_per_entity)):\n",
    "                #print(len(retrivedResult))\n",
    "                #print(role)\n",
    "                #print(num_actual_entities_with_role)\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            if TP ==  num_actual_entities_with_role[role]:\n",
    "                precision1[role] = precision1[role] + 1\n",
    "            else:\n",
    "                precision1[role] = precision1[role] + float(TP)/min(K, num_per_entity)\n",
    "                \n",
    "    for role in loc_tag_list:\n",
    "        role_word = type_word_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in loc_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0], role_word)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_loc_entity)):\n",
    "                #print(len(retrivedResult))\n",
    "                #print(role)\n",
    "                #print(num_actual_entities_with_role)\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            if TP ==  num_actual_entities_with_role[role]:\n",
    "                precision1[role] = precision1[role] + 1\n",
    "            else:\n",
    "                precision1[role] = precision1[role] + float(TP)/min(K, num_loc_entity)\n",
    "                \n",
    "    for role in org_tag_list:\n",
    "        role_word = type_word_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in org_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0], role_word)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_org_entity)):\n",
    "                \n",
    "                #print(len(retrivedResult))\n",
    "                #print(role)\n",
    "                #print(num_actual_entities_with_role)\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            if TP ==  num_actual_entities_with_role[role]:\n",
    "                precision1[role] = precision1[role] + 1\n",
    "            else:\n",
    "                precision1[role] = precision1[role] + float(TP)/min(K, num_org_entity)\n",
    "    #print(num_actual_entities_with_role)\n",
    "    #count = 1\n",
    "\n",
    "for tag in tag_list:\n",
    "    if doc_count_for_tag[tag] > 0:\n",
    "        print(tag, float(precision1[tag] * 100)/doc_count_for_tag[tag], '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
