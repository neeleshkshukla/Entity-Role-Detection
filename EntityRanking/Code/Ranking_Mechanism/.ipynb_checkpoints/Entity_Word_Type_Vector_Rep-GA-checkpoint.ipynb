{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code Tests following configuration:\n",
    "\n",
    "Entity Representation: Context words + Words in Entity\n",
    "\n",
    "Type Representation: Type representation learned on training corpus\n",
    "\n",
    "Ranking Score: Group Average\n",
    "\n",
    "Word Representation: Trained word vectors on corpus initialized with pretrained glove vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, logging\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, Phrases, phrases, KeyedVectors\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_ranking_op_folder = '../../Data/output'\n",
    "type_rep_folder = 'TypeRep/type_word/train'\n",
    "entity_rep_test_folder = 'EntityRep/test'\n",
    "entity_context_word_file = 'doc_entity_context_word.p'\n",
    "type_rep_file_name = 'tag_vec_dict.p'\n",
    "\n",
    "word_emnbedding_pretrained_trained_on_corpus = '../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt'\n",
    "\n",
    "entity_context_word_file = os.path.join(entity_ranking_op_folder, entity_rep_test_folder, entity_context_word_file)\n",
    "type_rep_file = os.path.join(entity_ranking_op_folder, type_rep_folder, type_rep_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = ['LOC_Event', 'LOC_Accused', 'LOC_Victim', 'LOC_Others', 'ORG_Accused', 'ORG_Victim', 'ORG_Others', 'PER_Victim', 'PER_Others', 'PER_Accused']\n",
    "per_tag_list = ['PER_Victim', 'PER_Others', 'PER_Accused']\n",
    "loc_tag_list = ['LOC_Event', 'LOC_Accused', 'LOC_Victim', 'LOC_Others']\n",
    "org_tag_list = ['ORG_Accused', 'ORG_Victim', 'ORG_Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-03 05:47:53,368 : INFO : loading projection weights from ../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt\n",
      "2018-05-03 05:50:28,309 : INFO : loaded (408497, 300) matrix from ../../trained_word_embeddings/word2vec/word_pretrain_trained_on_corpus/w2v_pretain_corpus_trained_gensim_300.txt\n"
     ]
    }
   ],
   "source": [
    "entity_rep_context_word_file_dict = pickle.load(open(entity_context_word_file, 'rb'))\n",
    "type_rep_dict = pickle.load(open(type_rep_file, 'rb'))\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word_emnbedding_pretrained_trained_on_corpus, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = word_vectors.get_vector('Narendra')\n",
    "size = len(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_average(entity, role):\n",
    "    num_of_words_in_entity = len(entity)\n",
    "    num_of_words_in_role = 1\n",
    "    total_number_of_words = num_of_words_in_entity + num_of_words_in_role\n",
    "    \n",
    "    sum_of_entity_type_word_vec = np.zeros(size)\n",
    "    for word in entity:\n",
    "        try:\n",
    "            word_vec = word_vectors.get_vector(word)\n",
    "            word_vec = word_vec/np.linalg.norm(word_vec)\n",
    "        except KeyError:\n",
    "            word_vec = np.zeros(size)\n",
    "            \n",
    "        sum_of_entity_type_word_vec = np.add(sum_of_entity_type_word_vec, word_vec)\n",
    "    \n",
    "    role = role/np.linalg.norm(role)\n",
    "    sum_of_entity_type_word_vec = np.add(sum_of_entity_type_word_vec, role)\n",
    "    \n",
    "    dot_product = np.dot(sum_of_entity_type_word_vec, sum_of_entity_type_word_vec)\n",
    "    group_avg = float(dot_product - (total_number_of_words))/(total_number_of_words * (total_number_of_words - 1))\n",
    "    return group_avg    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'R.C.' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9395f8370fb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mper_entities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mretrivedResult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mretrivedResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrivedResult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-caabec38efe4>\u001b[0m in \u001b[0;36mgroup_average\u001b[0;34m(entity, role)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msum_of_entity_type_word_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mword_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mword_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vec\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msum_of_entity_type_word_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_of_entity_type_word_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'R.C.' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "precision1 = dict()\n",
    "doc_count_for_tag = dict()\n",
    "\n",
    "for tag in tag_list:\n",
    "    doc_count_for_tag[tag] = 0\n",
    "    precision1[tag] = 0\n",
    "    \n",
    "\n",
    "# Precision at K\n",
    "K = 3\n",
    "count = 0\n",
    "for doc_id in entity_rep_context_word_file_dict:\n",
    "    #print(doc_id)\n",
    "    num_actual_entities_with_role = dict()\n",
    "    if count > 0:\n",
    "        break\n",
    "    per_entities = list()\n",
    "    loc_entities = list()\n",
    "    org_entities = list()\n",
    "    doc_role_dict = entity_rep_context_word_file_dict[doc_id]\n",
    "    for role in doc_role_dict.keys():\n",
    "        entities = doc_role_dict[role]\n",
    "        num_actual_entities_with_role[role] = len(entities)\n",
    "        if role in per_tag_list:\n",
    "            for entity in entities:\n",
    "                per_entities.append((entity, role))\n",
    "        if role in org_tag_list:\n",
    "            for entity in entities:\n",
    "                org_entities.append((entity, role))\n",
    "        if role in loc_tag_list:\n",
    "            for entity in entities:\n",
    "                loc_entities.append((entity, role))\n",
    "    \n",
    "    num_per_entity = len(per_entities)\n",
    "    num_org_entity = len(org_entities)\n",
    "    num_loc_entity = len(loc_entities)\n",
    "    \n",
    "    for role in per_tag_list:\n",
    "        role_vector = type_rep_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in per_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0], role_vector)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_per_entity)):\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            if TP ==  num_actual_entities_with_role[role]:\n",
    "                precision1[role] = precision1[role] + 1\n",
    "            else:\n",
    "                precision1[role] = precision1[role] + float(TP)/min(K, num_per_entity)\n",
    "                \n",
    "    for role in loc_tag_list:\n",
    "        role_vector = type_rep_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in loc_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0], role_vector)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_loc_entity)):\n",
    "                #print(len(retrivedResult))\n",
    "                #print(role)\n",
    "                #print(num_actual_entities_with_role)\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            if TP ==  num_actual_entities_with_role[role]:\n",
    "                precision1[role] = precision1[role] + 1\n",
    "            else:\n",
    "                precision1[role] = precision1[role] + float(TP)/min(K, num_loc_entity)\n",
    "                \n",
    "    for role in org_tag_list:\n",
    "        role_vector = type_rep_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in org_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0], role_vector)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_org_entity)):\n",
    "                \n",
    "                #print(len(retrivedResult))\n",
    "                #print(role)\n",
    "                #print(num_actual_entities_with_role)\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "            if TP ==  num_actual_entities_with_role[role]:\n",
    "                precision1[role] = precision1[role] + 1\n",
    "            else:\n",
    "                precision1[role] = precision1[role] + float(TP)/min(K, num_org_entity)\n",
    "    #print(num_actual_entities_with_role)\n",
    "    #count = 1\n",
    "\n",
    "for tag in tag_list:\n",
    "    if doc_count_for_tag[tag] > 0:\n",
    "        print(tag, float(precision1[tag] * 100)/doc_count_for_tag[tag], '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
