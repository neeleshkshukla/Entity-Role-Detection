{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code Tests following configuration:\n",
    "\n",
    "Entity Representation: Words in Entity and Context Words\n",
    "\n",
    "Type Representation: Similar words to type representation learned on training corpus\n",
    "\n",
    "Ranking Score: Group Average\n",
    "\n",
    "Word Representation: Trained word vectors on corpus initialized random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, logging, pickle\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, Phrases, phrases, KeyedVectors\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_ranking_op_folder = '../../Data/output'\n",
    "type_rep_folder = 'TypeRep/type_word/train'\n",
    "entity_rep_test_folder = 'EntityRep/test'\n",
    "entity_context_word_file = 'doc_entity_context_word.p'\n",
    "entity_doc_level_context_word_file = 'doc_entity_doc_level_context_word.p'\n",
    "type_word_file_name = 'tag_word_dict.p'\n",
    "\n",
    "doc_level = False\n",
    "sent_level = True\n",
    "\n",
    "word_emnbedding_trained_on_corpus = '../../trained_word_embeddings/word2vec/word_trained_from_corpus/w2v_corpus_trained_gensim_300.txt'\n",
    "\n",
    "entity_context_word_file = os.path.join(entity_ranking_op_folder, entity_rep_test_folder, entity_context_word_file)\n",
    "entity_doc_level_context_word_file = os.path.join(entity_ranking_op_folder, entity_rep_test_folder, entity_doc_level_context_word_file)\n",
    "type_word_file = os.path.join(entity_ranking_op_folder, type_rep_folder, type_word_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = ['LOC_Event', 'LOC_Accused', 'LOC_Victim', 'LOC_Others', 'ORG_Accused', 'ORG_Victim', 'ORG_Others', 'PER_Victim', 'PER_Others', 'PER_Accused']\n",
    "per_tag_list = ['PER_Victim', 'PER_Others', 'PER_Accused']\n",
    "loc_tag_list = ['LOC_Event', 'LOC_Accused', 'LOC_Victim', 'LOC_Others']\n",
    "org_tag_list = ['ORG_Accused', 'ORG_Victim', 'ORG_Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sent_level:\n",
    "    entity_rep_context_word_file_dict = pickle.load(open(entity_context_word_file, 'rb'))\n",
    "if doc_level:\n",
    "    entity_rep_context_word_file_dict = pickle.load(open(entity_doc_level_context_word_file, 'rb'))\n",
    "type_word_dict = pickle.load(open(type_word_file, 'rb'))\n",
    "#for tag in tag_list:\n",
    "   # print(tag, type_word_dict[tag], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-19 01:43:11,248 : INFO : loading projection weights from ../../trained_word_embeddings/word2vec/word_trained_from_corpus/w2v_corpus_trained_gensim_300.txt\n",
      "2018-05-19 01:43:18,295 : INFO : loaded (18799, 300) matrix from ../../trained_word_embeddings/word2vec/word_trained_from_corpus/w2v_corpus_trained_gensim_300.txt\n"
     ]
    }
   ],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(word_emnbedding_trained_on_corpus, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "word_vector = word_vectors.get_vector('was')\n",
    "size = len(word_vector)\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_average(entity, role_tuple):\n",
    "    num_of_words_in_entity = len(entity)\n",
    "    num_of_words_in_role = len(role)\n",
    "    total_number_of_words = num_of_words_in_entity + num_of_words_in_role\n",
    "    \n",
    "    sum_of_entity_type_word_vec = np.zeros(size)\n",
    "    for word in entity:\n",
    "        try:\n",
    "            word_vec = word_vectors.get_vector(word)\n",
    "            word_vec = word_vec/np.linalg.norm(word_vec)\n",
    "        except KeyError:\n",
    "            word_vec = np.zeros(size)\n",
    "        sum_of_entity_type_word_vec = np.add(sum_of_entity_type_word_vec, word_vec)\n",
    "    \n",
    "    for tup in role_tuple:\n",
    "        try:\n",
    "            word_vec = word_vectors.get_vector(tup[0])\n",
    "            word_vec = word_vec/np.linalg.norm(word_vec)\n",
    "        except KeyError:\n",
    "            word_vec = np.zeros(size)\n",
    "        sum_of_entity_type_word_vec = np.add(sum_of_entity_type_word_vec, word_vec)\n",
    "        \n",
    "    dot_product = np.dot(sum_of_entity_type_word_vec, sum_of_entity_type_word_vec)\n",
    "    group_avg = float(dot_product - (total_number_of_words))/(total_number_of_words * (total_number_of_words - 1))\n",
    "    return group_avg    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC_Event 66.30385487528342 %\n",
      "LOC_Accused 39.092970521541936 %\n",
      "LOC_Victim 62.77777777777778 %\n",
      "LOC_Others 67.7586493679308 %\n",
      "ORG_Accused 66.09460946094609 %\n",
      "ORG_Victim 48.39080459770116 %\n",
      "ORG_Others 81.14862707535121 %\n",
      "PER_Victim 55.78405017921146 %\n",
      "PER_Others 83.74273783587508 %\n",
      "PER_Accused 75.6754185692542 %\n",
      "Mean Average Precision 64.67695002608733 %\n"
     ]
    }
   ],
   "source": [
    "precision1 = dict()\n",
    "doc_count_for_tag = dict()\n",
    "AveP = dict()\n",
    "\n",
    "for tag in tag_list:\n",
    "    doc_count_for_tag[tag] = 0\n",
    "    precision1[tag] = 0\n",
    "    AveP[tag] = 0\n",
    "    \n",
    "\n",
    "# Precision at K\n",
    "K = 5\n",
    "count = 0\n",
    "for doc_id in entity_rep_context_word_file_dict:\n",
    "    #print(doc_id)\n",
    "    num_actual_entities_with_role = dict()\n",
    "    if count > 0:\n",
    "        break\n",
    "    per_entities = list()\n",
    "    loc_entities = list()\n",
    "    org_entities = list()\n",
    "    doc_role_dict = entity_rep_context_word_file_dict[doc_id]\n",
    "    for role in doc_role_dict.keys():\n",
    "        entities = doc_role_dict[role]\n",
    "        num_actual_entities_with_role[role] = len(entities)\n",
    "        if role in per_tag_list:\n",
    "            for entity in entities:\n",
    "                per_entities.append((entity, role))\n",
    "        if role in org_tag_list:\n",
    "            for entity in entities:\n",
    "                org_entities.append((entity, role))\n",
    "        if role in loc_tag_list:\n",
    "            for entity in entities:\n",
    "                loc_entities.append((entity, role))\n",
    "    \n",
    "    num_per_entity = len(per_entities)\n",
    "    num_org_entity = len(org_entities)\n",
    "    num_loc_entity = len(loc_entities)\n",
    "    \n",
    "    for role in per_tag_list:\n",
    "        role_word = type_word_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            avp = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in per_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0][1], role_word)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_per_entity)):\n",
    "                #print(len(retrivedResult))\n",
    "                #print(role)\n",
    "                #print(num_actual_entities_with_role)\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "                    avp = avp + (float(TP)/(i+1))\n",
    "            #if TP ==  num_actual_entities_with_role[role]:\n",
    "             #   precision1[role] = precision1[role] + 1\n",
    "            #else:\n",
    "            precision1[role] = precision1[role] + float(TP)/min(K, num_per_entity)\n",
    "            if TP != 0:\n",
    "                AveP[role] = AveP[role] + float(avp)/TP\n",
    "                \n",
    "    for role in loc_tag_list:\n",
    "        role_word = type_word_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            avp = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in loc_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0][1], role_word)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_loc_entity)):\n",
    "                #print(len(retrivedResult))\n",
    "                #print(role)\n",
    "                #print(num_actual_entities_with_role)\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "                    avp = avp + (float(TP)/(i+1))\n",
    "            #if TP ==  num_actual_entities_with_role[role]:\n",
    "               # precision1[role] = precision1[role] + 1\n",
    "           # else:\n",
    "            precision1[role] = precision1[role] + float(TP)/min(K, num_loc_entity)\n",
    "            if TP != 0:\n",
    "                AveP[role] = AveP[role] + float(avp)/TP\n",
    "                \n",
    "    for role in org_tag_list:\n",
    "        role_word = type_word_dict[role]\n",
    "        retrivedResult = list()\n",
    "        if num_actual_entities_with_role[role] != 0:\n",
    "            TP = 0\n",
    "            avp = 0\n",
    "            doc_count_for_tag[role] = doc_count_for_tag[role] + 1\n",
    "            for entity in org_entities:\n",
    "                sim = 2\n",
    "                sim = group_average(entity[0][1], role_word)\n",
    "                retrivedResult.append((entity, sim))\n",
    "            retrivedResult = sorted(retrivedResult,key=itemgetter(1), reverse=True)\n",
    "            for i in range(min(K, num_org_entity)):\n",
    "                \n",
    "                #print(len(retrivedResult))\n",
    "                #print(role)\n",
    "                #print(num_actual_entities_with_role)\n",
    "                if retrivedResult[i][0][1] == role:\n",
    "                    TP = TP + 1\n",
    "                    avp = avp + (float(TP)/(i+1))\n",
    "            #if TP ==  num_actual_entities_with_role[role]:\n",
    "             #   precision1[role] = precision1[role] + 1\n",
    "            #else:\n",
    "            precision1[role] = precision1[role] + float(TP)/min(K, num_org_entity)\n",
    "            if TP != 0:\n",
    "                AveP[role] = AveP[role] + float(avp)/TP\n",
    "    #print(num_actual_entities_with_role)\n",
    "    #count = 1\n",
    "avg_pre = 0\n",
    "mean_avg_pre = 0\n",
    "for tag in tag_list:\n",
    "    if doc_count_for_tag[tag] > 0:\n",
    "        avg_pre = avg_pre + float(precision1[tag] * 100)/doc_count_for_tag[tag]\n",
    "        mean_avg_pre = mean_avg_pre + float(AveP[tag] * 100)/doc_count_for_tag[tag]\n",
    "        #print(tag, float(precision1[tag] * 100)/doc_count_for_tag[tag], '%')\n",
    "        print(tag, float(AveP[tag] * 100)/doc_count_for_tag[tag], '%')\n",
    "#print('Average', avg_pre/10, '%')\n",
    "print('Mean Average Precision', mean_avg_pre/10, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
