{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.0\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1051\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "# Divide in train and test files [80:20] \n",
    "\n",
    "# Directory having content\n",
    "\n",
    "doc_dir = 'Data/content'\n",
    "\n",
    "train_file_list = []\n",
    "test_file_list = []\n",
    "\n",
    "for f in os.listdir(doc_dir):\n",
    "    #Random Sampling\n",
    "    if np.random.uniform(0,1)< 0.8:\n",
    "        train_file_list.append(f)\n",
    "    else:\n",
    "        test_file_list.append(f)\n",
    "\n",
    "print len(train_file_list)\n",
    "print len(test_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Five', 'O'), ('people', 'O'), ('were', 'O'), ('killed', 'O'), ('and', 'O'), ('over', 'O'), ('50', 'O'), ('injured', 'O'), ('in', 'O'), ('three', 'O'), ('blasts', 'O'), ('set', 'O'), ('off', 'O'), ('by', 'O'), ('insurgent', 'O'), ('outfit', 'O'), ('ULFA', 'ORG_Others'), ('here', 'O'), ('today', 'O'), ('hours', 'O'), ('before', 'O'), ('Union', 'O'), ('Home', 'O'), ('Minister', 'O'), ('P', 'PER_Others'), ('Chidambaram', 'PER_Others'), (\"'s\", 'O'), ('visit', 'O'), ('to', 'O'), ('review', 'O'), ('law', 'O'), ('and', 'O'), ('order', 'O'), ('situation', 'O'), ('in', 'O'), ('the', 'O'), ('state', 'O'), ('rocked', 'O'), ('by', 'O'), ('deadly', 'O'), ('blasts', 'O'), ('that', 'O'), ('left', 'O'), ('88', 'O'), ('dead', 'O'), ('two', 'O'), ('months', 'O'), ('ago', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('Three', 'O'), ('people', 'O'), ('were', 'O'), ('killed', 'O'), ('and', 'O'), ('35', 'O'), ('injured', 'O'), (',', 'O'), ('including', 'O'), ('four', 'O'), ('women', 'O'), (',', 'O'), ('when', 'O'), ('a', 'O'), ('bomb', 'O'), ('planted', 'O'), ('in', 'O'), ('front', 'O'), ('of', 'O'), ('a', 'O'), ('closed', 'O'), ('sweet', 'O'), ('shop', 'O'), ('exploded', 'O'), ('near', 'O'), ('upmarket', 'O'), ('Bhangagarh', 'LOC_Event'), ('flyover', 'O'), ('on', 'O'), ('the', 'O'), ('busy', 'O'), ('Guwahati-Shillong', 'O'), ('road', 'O'), ('at', 'O'), ('around', 'O'), ('5:45', 'O'), ('pm', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('Two', 'O'), ('persons', 'O'), ('died', 'O'), ('on', 'O'), ('way', 'O'), ('to', 'O'), ('hospital', 'O'), ('while', 'O'), ('another', 'O'), ('succumbed', 'O'), ('to', 'O'), ('his', 'O'), ('injuries', 'O'), ('at', 'O'), ('the', 'O'), ('Guwahati', 'ORG_Others'), ('Medical', 'ORG_Others'), ('College', 'ORG_Others'), ('Hospital', 'ORG_Others'), (',', 'O'), ('DGP', 'O'), ('G', 'O'), ('M', 'O'), ('Srivastava', 'PER_Others'), ('said', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('Two', 'O'), ('of', 'O'), ('the', 'O'), ('dead', 'O'), ('were', 'O'), ('identified', 'O'), ('as', 'O'), ('Amal', 'PER_Victim'), ('Das', 'PER_Victim'), ('and', 'O'), ('Kahil', 'PER_Victim'), ('Sheikh', 'PER_Victim'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('A', 'O'), ('bomb', 'O'), ('kept', 'O'), ('in', 'O'), ('a', 'O'), ('bicycle', 'O'), ('exploded', 'O'), ('at', 'O'), ('a', 'O'), ('market', 'O'), ('in', 'O'), ('the', 'O'), ('Bhootnath', 'LOC_Event'), ('area', 'O'), (',', 'O'), ('the', 'O'), ('route', 'O'), ('which', 'O'), ('Chidambaram', 'PER_Others'), ('was', 'O'), ('to', 'O'), ('take', 'O'), ('on', 'O'), ('his', 'O'), ('way', 'O'), ('from', 'O'), ('the', 'O'), ('airport', 'O'), (',', 'O'), ('under', 'O'), ('Baralumukh', 'LOC_Others'), ('police', 'O'), ('station', 'O'), ('around', 'O'), ('5.30', 'O'), ('pm', 'O'), ('in', 'O'), ('which', 'O'), ('two', 'O'), ('persons', 'O'), ('were', 'O'), ('killed', 'O'), ('and', 'O'), ('12', 'O'), ('others', 'O'), ('injured', 'O'), (',', 'O'), ('official', 'O'), ('sources', 'O'), ('said', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('An', 'O'), ('Improvised', 'O'), ('Explosive', 'O'), ('Devise', 'O'), ('(', 'O'), ('IED', 'O'), (')', 'O'), ('kept', 'O'), ('in', 'O'), ('a', 'O'), ('Gauhati', 'O'), ('Municipal', 'O'), ('Corporation', 'O'), ('(', 'O'), ('GMC', 'O'), (')', 'O'), ('dustbin', 'O'), ('went', 'O'), ('off', 'O'), ('at', 'O'), ('around', 'O'), ('3.30', 'O'), ('pm', 'O'), ('injuring', 'O'), ('three', 'O'), ('persons', 'O'), ('in', 'O'), ('Birubari', 'LOC_Event'), ('Tiniali', 'LOC_Event'), ('area', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('The', 'O'), ('blasts', 'O'), ('came', 'O'), ('a', 'O'), ('day', 'O'), ('ahead', 'O'), ('of', 'O'), ('Prime', 'O'), ('Minister', 'O'), ('Manmohan', 'PER_Others'), ('Singh', 'PER_Others'), (\"'s\", 'O'), ('arrival', 'O'), ('here', 'O'), ('tomorrow', 'O'), ('enroute', 'O'), ('Shillong', 'LOC_Others'), ('to', 'O'), ('inaugurate', 'O'), ('the', 'O'), ('Indian', 'ORG_Others'), ('Science', 'ORG_Others'), ('Congress', 'ORG_Others'), ('there', 'O'), ('on', 'O'), ('January', 'O'), ('three', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('Chidmabaram', 'PER_Others'), ('arrived', 'O'), ('at', 'O'), ('the', 'O'), ('Lokopriyo', 'LOC_Others'), ('Gopinath', 'LOC_Others'), ('Bordoloi', 'LOC_Others'), ('international', 'LOC_Others'), ('airport', 'LOC_Others'), ('on', 'O'), ('a', 'O'), ('two-day', 'O'), ('visit', 'O'), ('to', 'O'), ('the', 'O'), ('state', 'O'), ('to', 'O'), ('review', 'O'), ('Assam', 'LOC_Event'), (\"'s\", 'O'), ('law', 'O'), ('and', 'O'), ('order', 'O'), ('situation', 'O'), ('and', 'O'), ('attend', 'O'), ('a', 'O'), ('meeting', 'O'), ('of', 'O'), ('the', 'O'), ('Unified', 'O'), ('Command', 'O'), ('headed', 'O'), ('by', 'O'), ('Chief', 'O'), ('Minister', 'O'), ('Tarun', 'PER_Others'), ('Gogoi', 'PER_Others'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# Build Tagged dataset to be fed in nltk hmm tagger\n",
    "# It is a list of tagged sentences. \n",
    "# training_data = [ [(word, tag), (word, tag).....]\n",
    "# [(word, tag), (word, tag).....]\n",
    "#]\n",
    "\n",
    "# Directory having tags\n",
    "tag_dir = 'Data/new_tags'\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for f in train_file_list:\n",
    "    training_sentences =[]\n",
    "    word_file_path = os.path.join(doc_dir, f)\n",
    "    tag_file_path = os.path.join(tag_dir, f)\n",
    "    lines_in_word_file = []\n",
    "    lines_in_tag_file = []\n",
    "    with open(word_file_path, \"rt\") as word_file:\n",
    "        for line in word_file:\n",
    "            lines_in_word_file.append(line)\n",
    "    with open(tag_file_path, \"rt\") as tag_file:\n",
    "        for line in tag_file:\n",
    "            lines_in_tag_file.append(line)\n",
    "    if (len(lines_in_word_file) == len(lines_in_tag_file)) and len(lines_in_word_file) > 0:\n",
    "        for i in xrange(len(lines_in_word_file)):\n",
    "            word_in_file = lines_in_word_file[i].split()\n",
    "            tag_in_file = lines_in_tag_file[i].split()\n",
    "            pairs_in_line = []\n",
    "            length = min(len(word_in_file), len(tag_in_file))\n",
    "            #Create the word_tag pair\n",
    "            for j in xrange(length):\n",
    "                pairs_in_line.append((word_in_file[j], tag_in_file[j]));\n",
    "            training_sentences.append(pairs_in_line)\n",
    "    if len(training_sentences) > 0:\n",
    "        training_data.extend(training_sentences)\n",
    "\n",
    "print training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        tag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:tag1=' + tag1,\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "        \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2tags(sent):\n",
    "    return [tag for word, tag in sent]\n",
    "\n",
    "def sent2words(sent):\n",
    "    return [word for word, tag in sent] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Five', 'O'), ('people', 'O'), ('were', 'O'), ('killed', 'O'), ('and', 'O'), ('over', 'O'), ('50', 'O'), ('injured', 'O'), ('in', 'O'), ('three', 'O'), ('blasts', 'O'), ('set', 'O'), ('off', 'O'), ('by', 'O'), ('insurgent', 'O'), ('outfit', 'O'), ('ULFA', 'ORG_Others'), ('here', 'O'), ('today', 'O'), ('hours', 'O'), ('before', 'O'), ('Union', 'O'), ('Home', 'O'), ('Minister', 'O'), ('P', 'PER_Others'), ('Chidambaram', 'PER_Others'), (\"'s\", 'O'), ('visit', 'O'), ('to', 'O'), ('review', 'O'), ('law', 'O'), ('and', 'O'), ('order', 'O'), ('situation', 'O'), ('in', 'O'), ('the', 'O'), ('state', 'O'), ('rocked', 'O'), ('by', 'O'), ('deadly', 'O'), ('blasts', 'O'), ('that', 'O'), ('left', 'O'), ('88', 'O'), ('dead', 'O'), ('two', 'O'), ('months', 'O'), ('ago', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('Three', 'O'), ('people', 'O'), ('were', 'O'), ('killed', 'O'), ('and', 'O'), ('35', 'O'), ('injured', 'O'), (',', 'O'), ('including', 'O'), ('four', 'O'), ('women', 'O'), (',', 'O'), ('when', 'O'), ('a', 'O'), ('bomb', 'O'), ('planted', 'O'), ('in', 'O'), ('front', 'O'), ('of', 'O'), ('a', 'O'), ('closed', 'O'), ('sweet', 'O'), ('shop', 'O'), ('exploded', 'O'), ('near', 'O'), ('upmarket', 'O'), ('Bhangagarh', 'LOC_Event'), ('flyover', 'O'), ('on', 'O'), ('the', 'O'), ('busy', 'O'), ('Guwahati-Shillong', 'O'), ('road', 'O'), ('at', 'O'), ('around', 'O'), ('5:45', 'O'), ('pm', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('Two', 'O'), ('persons', 'O'), ('died', 'O'), ('on', 'O'), ('way', 'O'), ('to', 'O'), ('hospital', 'O'), ('while', 'O'), ('another', 'O'), ('succumbed', 'O'), ('to', 'O'), ('his', 'O'), ('injuries', 'O'), ('at', 'O'), ('the', 'O'), ('Guwahati', 'ORG_Others'), ('Medical', 'ORG_Others'), ('College', 'ORG_Others'), ('Hospital', 'ORG_Others'), (',', 'O'), ('DGP', 'O'), ('G', 'O'), ('M', 'O'), ('Srivastava', 'PER_Others'), ('said', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('Two', 'O'), ('of', 'O'), ('the', 'O'), ('dead', 'O'), ('were', 'O'), ('identified', 'O'), ('as', 'O'), ('Amal', 'PER_Victim'), ('Das', 'PER_Victim'), ('and', 'O'), ('Kahil', 'PER_Victim'), ('Sheikh', 'PER_Victim'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('A', 'O'), ('bomb', 'O'), ('kept', 'O'), ('in', 'O'), ('a', 'O'), ('bicycle', 'O'), ('exploded', 'O'), ('at', 'O'), ('a', 'O'), ('market', 'O'), ('in', 'O'), ('the', 'O'), ('Bhootnath', 'LOC_Event'), ('area', 'O'), (',', 'O'), ('the', 'O'), ('route', 'O'), ('which', 'O'), ('Chidambaram', 'PER_Others'), ('was', 'O'), ('to', 'O'), ('take', 'O'), ('on', 'O'), ('his', 'O'), ('way', 'O'), ('from', 'O'), ('the', 'O'), ('airport', 'O'), (',', 'O'), ('under', 'O'), ('Baralumukh', 'LOC_Others'), ('police', 'O'), ('station', 'O'), ('around', 'O'), ('5.30', 'O'), ('pm', 'O'), ('in', 'O'), ('which', 'O'), ('two', 'O'), ('persons', 'O'), ('were', 'O'), ('killed', 'O'), ('and', 'O'), ('12', 'O'), ('others', 'O'), ('injured', 'O'), (',', 'O'), ('official', 'O'), ('sources', 'O'), ('said', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('An', 'O'), ('Improvised', 'O'), ('Explosive', 'O'), ('Devise', 'O'), ('(', 'O'), ('IED', 'O'), (')', 'O'), ('kept', 'O'), ('in', 'O'), ('a', 'O'), ('Gauhati', 'O'), ('Municipal', 'O'), ('Corporation', 'O'), ('(', 'O'), ('GMC', 'O'), (')', 'O'), ('dustbin', 'O'), ('went', 'O'), ('off', 'O'), ('at', 'O'), ('around', 'O'), ('3.30', 'O'), ('pm', 'O'), ('injuring', 'O'), ('three', 'O'), ('persons', 'O'), ('in', 'O'), ('Birubari', 'LOC_Event'), ('Tiniali', 'LOC_Event'), ('area', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('The', 'O'), ('blasts', 'O'), ('came', 'O'), ('a', 'O'), ('day', 'O'), ('ahead', 'O'), ('of', 'O'), ('Prime', 'O'), ('Minister', 'O'), ('Manmohan', 'PER_Others'), ('Singh', 'PER_Others'), (\"'s\", 'O'), ('arrival', 'O'), ('here', 'O'), ('tomorrow', 'O'), ('enroute', 'O'), ('Shillong', 'LOC_Others'), ('to', 'O'), ('inaugurate', 'O'), ('the', 'O'), ('Indian', 'ORG_Others'), ('Science', 'ORG_Others'), ('Congress', 'ORG_Others'), ('there', 'O'), ('on', 'O'), ('January', 'O'), ('three', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('Chidmabaram', 'PER_Others'), ('arrived', 'O'), ('at', 'O'), ('the', 'O'), ('Lokopriyo', 'LOC_Others'), ('Gopinath', 'LOC_Others'), ('Bordoloi', 'LOC_Others'), ('international', 'LOC_Others'), ('airport', 'LOC_Others'), ('on', 'O'), ('a', 'O'), ('two-day', 'O'), ('visit', 'O'), ('to', 'O'), ('the', 'O'), ('state', 'O'), ('to', 'O'), ('review', 'O'), ('Assam', 'LOC_Event'), (\"'s\", 'O'), ('law', 'O'), ('and', 'O'), ('order', 'O'), ('situation', 'O'), ('and', 'O'), ('attend', 'O'), ('a', 'O'), ('meeting', 'O'), ('of', 'O'), ('the', 'O'), ('Unified', 'O'), ('Command', 'O'), ('headed', 'O'), ('by', 'O'), ('Chief', 'O'), ('Minister', 'O'), ('Tarun', 'PER_Others'), ('Gogoi', 'PER_Others'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O')]\n",
      "['bias', 'word.lower=five', 'word[-3:]=ive', 'word[-2:]=ve', 'word.isupper=False', 'word.istitle=True', 'word.isdigit=False', 'BOS', '+1:word.lower=people', '+1:word.istitle=False', '+1:word.isupper=False']\n",
      "O\n",
      "Five\n"
     ]
    }
   ],
   "source": [
    "print training_data[0]\n",
    "print sent2features(training_data[0])[0]\n",
    "print sent2tags(training_data[0])[0]\n",
    "print sent2words(training_data[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [sent2features(s) for s in training_data]\n",
    "y_train = [sent2tags(s) for s in training_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(x_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and save the model\n",
    "trainer.train('osint-bomb-blast.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f4779c22250>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('osint-bomb-blast.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Atiq', 'PER_Others'), ('Khan', 'PER_Others'), ('.', 'O'), ('.', 'O'), ('LUCKNOW', 'LOC_Others'), (':', 'O'), ('The', 'ORG_Others'), ('Anti-Terrorism', 'ORG_Others'), ('Squad', 'ORG_Others'), ('-LRB-', 'O'), ('ATS', 'ORG_Others'), ('-RRB-', 'O'), (',', 'O'), ('Mumbai', 'LOC_Others'), (',', 'O'), ('on', 'O'), ('Thursday', 'O'), ('secured', 'O'), ('the', 'O'), ('transit', 'O'), ('remand', 'O'), ('for', 'O'), ('Sudhakar', 'PER_Accused'), ('Dwivedi', 'PER_Accused'), (',', 'O'), ('alias', 'O'), ('Amritanand', 'PER_Accused'), (',', 'O'), ('a', 'O'), ('suspect', 'O'), ('in', 'O'), ('the', 'O'), ('Malegaon', 'LOC_Event'), ('bomb', 'O'), ('blast', 'O'), ('case', 'O'), ('of', 'O'), ('September', 'O'), (',', 'O'), ('2008', 'O'), ('.', 'O'), ('The', 'O'), ('remand', 'O'), ('till', 'O'), ('November', 'O'), ('16', 'O'), ('was', 'O'), ('granted', 'O'), ('by', 'O'), ('Mukesh', 'PER_Others'), ('Kumar', 'PER_Others'), (',', 'O'), ('Civil', 'O'), ('Judge', 'O'), (',', 'O'), ('Junior', 'O'), ('Division', 'O'), (',', 'O'), ('Lucknow', 'LOC_Others'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('His', 'O'), ('name', 'O'), ('had', 'O'), ('earlier', 'O'), ('been', 'O'), ('disclosed', 'O'), ('as', 'O'), ('Dayanand', 'PER_Others'), ('Pandey', 'PER_Others'), ('but', 'O'), (',', 'O'), ('following', 'O'), ('calls', 'O'), ('from', 'O'), ('the', 'O'), ('DGPs', 'O'), ('office', 'O'), ('late', 'O'), ('on', 'O'), ('Wednesday', 'O'), ('night', 'O'), (',', 'O'), ('it', 'O'), ('was', 'O'), ('given', 'O'), ('as', 'O'), ('Sudhakar', 'PER_Accused'), ('Dwivedi', 'PER_Others'), (',', 'O'), ('son', 'O'), ('of', 'O'), ('Dayanand', 'PER_Others'), ('Dwivedi', 'PER_Others'), ('.', 'O'), ('He', 'O'), ('had', 'O'), ('taken', 'O'), ('the', 'O'), ('name', 'O'), ('Amritanand', 'PER_Others'), ('and', 'O'), ('become', 'O'), ('the', 'O'), ('Peethadheeshwar', 'O'), ('of', 'O'), ('the', 'O'), ('Sharda', 'ORG_Others'), ('Sarvagya', 'ORG_Others'), ('Peeth', 'ORG_Others'), ('in', 'O'), ('Jammu', 'LOC_Others'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('Dwivedi', 'PER_Others'), ('was', 'O'), ('picked', 'O'), ('up', 'O'), ('by', 'O'), ('the', 'O'), ('Mumbai', 'LOC_Others'), ('ATS', 'ORG_Others'), ('from', 'O'), ('the', 'O'), ('residence', 'O'), ('of', 'O'), ('his', 'O'), ('brother', 'O'), (',', 'O'), ('Pushkar', 'PER_Accused'), ('Dwivedi', 'PER_Accused'), (',', 'O'), ('at', 'O'), ('Rawatpur', 'LOC_Others'), ('village', 'O'), ('in', 'O'), ('Kanpur', 'LOC_Others'), ('on', 'O'), ('Wednesday', 'O'), ('.', 'O'), ('He', 'O'), ('is', 'O'), ('to', 'O'), ('be', 'O'), ('taken', 'O'), ('to', 'O'), ('Mumbai', 'LOC_Others'), ('for', 'O'), ('further', 'O'), ('interrogation', 'O'), ('.', 'O'), ('.', 'O'), ('.', 'O'), ('Dwivedi', 'PER_Others'), ('was', 'O'), ('brought', 'O'), ('to', 'O'), ('Lucknow', 'LOC_Others'), ('on', 'O'), ('Wednesday', 'O'), ('night', 'O'), ('and', 'O'), ('was', 'O'), ('subjected', 'O'), ('to', 'O'), ('a', 'O'), ('detailed', 'O'), ('interrogation', 'O'), ('.', 'O'), ('Details', 'O'), ('of', 'O'), ('the', 'O'), ('closed-door', 'O'), ('interrogation', 'O'), ('were', 'O'), ('not', 'O'), ('known', 'O'), (',', 'O'), ('but', 'O'), ('sources', 'O'), ('said', 'O'), ('the', 'O'), ('ATS', 'ORG_Others'), ('was', 'O'), ('looking', 'O'), ('into', 'O'), ('his', 'O'), ('contacts', 'O'), ('with', 'O'), ('some', 'O'), ('Hindu', 'ORG_Others'), ('organisation', 'ORG_Others'), ('leaders', 'O'), ('of', 'O'), ('Central', 'O'), ('Uttar', 'LOC_Others'), ('Pradesh', 'LOC_Others'), ('.', 'O'), ('His', 'O'), ('name', 'O'), ('surfaced', 'O'), ('after', 'O'), ('the', 'O'), ('ATS', 'ORG_Others'), ('team', 'O'), (',', 'O'), ('conducting', 'O'), ('the', 'O'), ('investigation', 'O'), ('into', 'O'), ('the', 'O'), ('Malegaon', 'LOC_Event'), ('blasts', 'O'), ('and', 'O'), ('the', 'O'), ('alleged', 'O'), ('involvement', 'O'), ('of', 'O'), ('a', 'O'), ('retired', 'O'), ('Lieutenant-Colonel', 'O'), (',', 'O'), ('found', 'O'), ('that', 'O'), ('he', 'O'), ('was', 'O'), ('in', 'O'), ('touch', 'O'), ('with', 'O'), ('Sadhvi', 'PER_Accused'), ('Pragnya', 'PER_Accused'), ('Singh', 'PER_Accused'), (',', 'O'), ('another', 'O'), ('accused', 'O'), ('in', 'O'), ('the', 'O'), ('case', 'O'), (',', 'O'), ('the', 'O'), ('sources', 'O'), ('said', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# Create test data\n",
    "test_data = []\n",
    "for f in test_file_list:\n",
    "    test_sentences =[]\n",
    "    word_file_path = os.path.join(doc_dir, f)\n",
    "    tag_file_path = os.path.join(tag_dir, f)\n",
    "    lines_in_word_file = []\n",
    "    lines_in_tag_file = []\n",
    "    with open(word_file_path, \"rt\") as word_file:\n",
    "        for line in word_file:\n",
    "            lines_in_word_file.append(line)\n",
    "    with open(tag_file_path, \"rt\") as tag_file:\n",
    "        for line in tag_file:\n",
    "            lines_in_tag_file.append(line)\n",
    "    if (len(lines_in_word_file) == len(lines_in_tag_file)) and len(lines_in_word_file) > 0:\n",
    "        for i in xrange(len(lines_in_word_file)):\n",
    "            word_in_file = lines_in_word_file[i].split()\n",
    "            tag_in_file = lines_in_tag_file[i].split()\n",
    "            pairs_in_line = []\n",
    "            length = min(len(word_in_file), len(tag_in_file))\n",
    "            #Create the word_tag pair\n",
    "            for j in xrange(length):\n",
    "                pairs_in_line.append((word_in_file[j], tag_in_file[j]));\n",
    "            test_sentences.append(pairs_in_line)\n",
    "    if len(test_sentences) > 0:\n",
    "        test_data.extend(test_sentences)\n",
    "\n",
    "print test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atiq Khan . . LUCKNOW : The Anti-Terrorism Squad -LRB- ATS -RRB- , Mumbai , on Thursday secured the transit remand for Sudhakar Dwivedi , alias Amritanand , a suspect in the Malegaon bomb blast case of September , 2008 . The remand till November 16 was granted by Mukesh Kumar , Civil Judge , Junior Division , Lucknow . . . His name had earlier been disclosed as Dayanand Pandey but , following calls from the DGPs office late on Wednesday night , it was given as Sudhakar Dwivedi , son of Dayanand Dwivedi . He had taken the name Amritanand and become the Peethadheeshwar of the Sharda Sarvagya Peeth in Jammu . . . Dwivedi was picked up by the Mumbai ATS from the residence of his brother , Pushkar Dwivedi , at Rawatpur village in Kanpur on Wednesday . He is to be taken to Mumbai for further interrogation . . . Dwivedi was brought to Lucknow on Wednesday night and was subjected to a detailed interrogation . Details of the closed-door interrogation were not known , but sources said the ATS was looking into his contacts with some Hindu organisation leaders of Central Uttar Pradesh . His name surfaced after the ATS team , conducting the investigation into the Malegaon blasts and the alleged involvement of a retired Lieutenant-Colonel , found that he was in touch with Sadhvi Pragnya Singh , another accused in the case , the sources said .\n",
      "('Predicted:', 'PER_Others PER_Others O O LOC_Others O O ORG_Others ORG_Others O ORG_Others O O LOC_Others O O O O O O O O PER_Accused PER_Accused O O PER_Accused O O O O O LOC_Event O O O O O O O O O O O O O O O O PER_Others PER_Others O O O O O O O LOC_Others O O O O O O O O O O PER_Others PER_Others O O O O O O O O O O O O O O O O O PER_Accused PER_Accused O O O PER_Others PER_Others O O O O O O O O O O O O O ORG_Others ORG_Others ORG_Others O LOC_Others LOC_Others O O O O O O O O LOC_Event O O O O O O O O PER_Accused PER_Accused O O LOC_Others O O LOC_Others O O O O O O O O O LOC_Others O O O O O O O O O O LOC_Event O O O O O O O O O O O O O O O O O O O O O O O O ORG_Others O O O O O O O O O O O O LOC_Others LOC_Others O O O O O O ORG_Others O O O O O O O LOC_Event O O O O O O O O O O O O O O O O O PER_Accused PER_Accused PER_Accused O O O O O O O O O O O')\n",
      "('Correct:  ', 'PER_Others PER_Others O O LOC_Others O ORG_Others ORG_Others ORG_Others O ORG_Others O O LOC_Others O O O O O O O O PER_Accused PER_Accused O O PER_Accused O O O O O LOC_Event O O O O O O O O O O O O O O O O PER_Others PER_Others O O O O O O O LOC_Others O O O O O O O O O O PER_Others PER_Others O O O O O O O O O O O O O O O O O PER_Accused PER_Others O O O PER_Others PER_Others O O O O O O PER_Others O O O O O O ORG_Others ORG_Others ORG_Others O LOC_Others O O O PER_Others O O O O O LOC_Others ORG_Others O O O O O O O PER_Accused PER_Accused O O LOC_Others O O LOC_Others O O O O O O O O O LOC_Others O O O O O O PER_Others O O O LOC_Others O O O O O O O O O O O O O O O O O O O O O O O O ORG_Others O O O O O O O ORG_Others ORG_Others O O O LOC_Others LOC_Others O O O O O O ORG_Others O O O O O O O LOC_Event O O O O O O O O O O O O O O O O O PER_Accused PER_Accused PER_Accused O O O O O O O O O O O')\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_data[0]\n",
    "print(' '.join(sent2words(example_sent)))\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2tags(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [sent2features(s) for s in test_data]\n",
    "y_test = [sent2tags(s) for s in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 s, sys: 0 ns, total: 1.03 s\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [tagger.tag(xseq) for xseq in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Accused       0.96      0.82      0.88        55\n",
      "      Event       1.00      1.00      1.00       107\n",
      "LOC_Accused       0.72      0.31      0.43       152\n",
      "  LOC_Assoc       1.00      1.00      1.00       107\n",
      "  LOC_Event       0.71      0.62      0.66      1369\n",
      " LOC_Others       0.70      0.65      0.67      1847\n",
      " LOC_Victim       0.76      0.18      0.29        73\n",
      "   Location       0.79      0.74      0.76       159\n",
      "ORG_Accused       0.83      0.79      0.81       567\n",
      "  ORG_Assoc       1.00      0.10      0.17        21\n",
      " ORG_Others       0.83      0.71      0.76      1948\n",
      " ORG_Victim       0.77      0.63      0.69       106\n",
      "PER_Accused       0.83      0.61      0.70       882\n",
      "  PER_Assoc       0.69      0.92      0.79        39\n",
      " PER_Others       0.89      0.84      0.87      1713\n",
      " PER_Victim       0.95      0.72      0.82       302\n",
      "     Victim       0.38      0.60      0.46         5\n",
      "\n",
      "avg / total       0.80      0.70      0.74      9452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n",
      "254\n"
     ]
    }
   ],
   "source": [
    "num_test_data = len(y_test)\n",
    "print len(y_pred)\n",
    "print num_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "actual_tag_count = dict()\n",
    "matched_tag_count = dict()\n",
    "matched_tag_count['PER_Others'] = 0\n",
    "actual_tag_count['PER_Others'] = 0\n",
    "matched_tag_count['PER_Victim'] = 0\n",
    "actual_tag_count['PER_Victim'] = 0\n",
    "matched_tag_count['PER_Accused'] = 0\n",
    "actual_tag_count['PER_Accused'] = 0\n",
    "matched_tag_count['ORG_Victim'] = 0\n",
    "actual_tag_count['ORG_Victim'] = 0\n",
    "matched_tag_count['ORG_Accused'] = 0\n",
    "actual_tag_count['ORG_Accused'] = 0\n",
    "matched_tag_count['ORG_Others'] = 0\n",
    "actual_tag_count['ORG_Others'] = 0\n",
    "matched_tag_count['LOC_Accused'] = 0\n",
    "actual_tag_count['LOC_Accused'] = 0\n",
    "matched_tag_count['LOC_Others'] = 0\n",
    "actual_tag_count['LOC_Others'] = 0\n",
    "matched_tag_count['LOC_Event'] = 0\n",
    "actual_tag_count['LOC_Event'] = 0\n",
    "matched_tag_count['LOC_Victim'] = 0\n",
    "actual_tag_count['LOC_Victim'] = 0\n",
    "\n",
    "for i in xrange(num_test_data):\n",
    "    y_test_i = y_test[i]\n",
    "    y_pred_i = y_pred[i]\n",
    "    test_tag_length = len(y_test[i])\n",
    "    predicted_tag_length = len(y_pred[i])\n",
    "    for j in xrange(test_tag_length):\n",
    "        if y_test_i[j] in actual_tag_count.keys():\n",
    "            actual_tag_count[y_test_i[j]] = actual_tag_count[y_test_i[j]] + 1\n",
    "        \n",
    "        if y_test_i[j] == y_pred_i[j]:\n",
    "            if y_test_i[j] in matched_tag_count.keys():\n",
    "                matched_tag_count[y_test_i[j]] = matched_tag_count[y_test_i[j]] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Accuracy Class Wise =====================\n",
      "\n",
      "Class    Matched Total %\n",
      "--------------------------\n",
      "PER_Others: 1435 1713 83%\n",
      "PER_Victim: 217 302 71%\n",
      "PER_Accused: 536 882 60%\n",
      "ORG_Victim: 67 106 63%\n",
      "ORG_Accused: 450 567 79%\n",
      "ORG_Others: 1383 1948 70%\n",
      "LOC_Accused: 47 152 30%\n",
      "LOC_Others: 1195 1847 64%\n",
      "LOC_Event: 852 1369 62%\n",
      "LOC_Victim: 13 73 17%\n"
     ]
    }
   ],
   "source": [
    "print('======= Accuracy Class Wise =====================\\n')\n",
    "\n",
    "print('Class    Matched Total %')\n",
    "print('--------------------------')\n",
    "print ('PER_Others: '+str(matched_tag_count['PER_Others'])+ ' ' + str(actual_tag_count['PER_Others'])+ ' ' + str(matched_tag_count['PER_Others']*100/actual_tag_count['PER_Others'])+'%')\n",
    "print ('PER_Victim: '+str(matched_tag_count['PER_Victim'])+ ' ' + str(actual_tag_count['PER_Victim'])+ ' '+str(matched_tag_count['PER_Victim']*100/actual_tag_count['PER_Victim'])+'%')\n",
    "print ('PER_Accused: '+str(matched_tag_count['PER_Accused'])+ ' ' + str(actual_tag_count['PER_Accused'])+ ' '+str(matched_tag_count['PER_Accused']*100/actual_tag_count['PER_Accused'])+'%')\n",
    "print ('ORG_Victim: '+str(matched_tag_count['ORG_Victim']) + ' '+ str(actual_tag_count['ORG_Victim'])+ ' '+str(matched_tag_count['ORG_Victim']*100/actual_tag_count['ORG_Victim'])+'%')\n",
    "print ('ORG_Accused: '+str(matched_tag_count['ORG_Accused']) + ' '+ str(actual_tag_count['ORG_Accused'])+ ' '+str(matched_tag_count['ORG_Accused']*100/actual_tag_count['ORG_Accused'])+'%')\n",
    "print ('ORG_Others: '+str(matched_tag_count['ORG_Others']) + ' '+ str(actual_tag_count['ORG_Others'])+ ' '+str(matched_tag_count['ORG_Others']*100/actual_tag_count['ORG_Others'])+'%')\n",
    "print ('LOC_Accused: '+str(matched_tag_count['LOC_Accused'])+ ' ' + str(actual_tag_count['LOC_Accused'])+ ' '+str(matched_tag_count['LOC_Accused']*100/actual_tag_count['LOC_Accused'])+'%')\n",
    "print ('LOC_Others: '+str(matched_tag_count['LOC_Others'])+ ' ' + str(actual_tag_count['LOC_Others'])+ ' '+str(matched_tag_count['LOC_Others']*100/actual_tag_count['LOC_Others'])+'%')\n",
    "print ('LOC_Event: '+str(matched_tag_count['LOC_Event']) + ' '+ str(actual_tag_count['LOC_Event'])+ ' '+str(matched_tag_count['LOC_Event']*100/actual_tag_count['LOC_Event'])+'%')\n",
    "print ('LOC_Victim: '+str(matched_tag_count['LOC_Victim']) + ' '+ str(actual_tag_count['LOC_Victim'])+ ' '+str(matched_tag_count['LOC_Victim']*100/actual_tag_count['LOC_Victim'])+'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
