{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import CRFTagger\n",
    "import os\n",
    "import numpy as np\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset for NLTK HMM Tagger\n",
    "# Divide in train and test files [80:20] \n",
    "\n",
    "# Directory having content\n",
    "doc_dir = '../../../../Data/input/content'\n",
    "\n",
    "train_file_list = []\n",
    "test_file_list = []\n",
    "\n",
    "for f in os.listdir(doc_dir):\n",
    "    #Random Sampling\n",
    "    if np.random.uniform(0,1)< 0.8:\n",
    "        train_file_list.append(f)\n",
    "    else:\n",
    "        test_file_list.append(f)\n",
    "\n",
    "print (len(train_file_list))\n",
    "print (len(test_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Tagged dataset to be fed in nltk hmm tagger\n",
    "# It is a list of tagged sentences. \n",
    "# training_data = [ [(word, tag), (word, tag).....]\n",
    "# [(word, tag), (word, tag).....]\n",
    "#]\n",
    "\n",
    "# Directory having tags\n",
    "tag_dir = '../../../../Data/input/new_tags'\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for f in train_file_list:\n",
    "    training_sentences =[]\n",
    "    word_file_path = os.path.join(doc_dir, f)\n",
    "    tag_file_path = os.path.join(tag_dir, f)\n",
    "    lines_in_word_file = []\n",
    "    lines_in_tag_file = []\n",
    "    with io.open(word_file_path, \"rt\", encoding=\"utf-8\") as word_file:\n",
    "        for line in word_file:\n",
    "            lines_in_word_file.append(line)\n",
    "    with io.open(tag_file_path, \"rt\", encoding=\"utf-8\") as tag_file:\n",
    "        for line in tag_file:\n",
    "            lines_in_tag_file.append(line)\n",
    "    if (len(lines_in_word_file) == len(lines_in_tag_file)) and len(lines_in_word_file) > 0:\n",
    "        for i in range(len(lines_in_word_file)):\n",
    "            word_in_file = lines_in_word_file[i].split()\n",
    "            tag_in_file = lines_in_tag_file[i].split()\n",
    "            pairs_in_line = []\n",
    "            length = min(len(word_in_file), len(tag_in_file))\n",
    "            #Create the word_tag pair\n",
    "            for j in range(length):\n",
    "                pairs_in_line.append((word_in_file[j], tag_in_file[j]));\n",
    "            training_sentences.append(pairs_in_line)\n",
    "    if len(training_sentences) > 0:\n",
    "        training_data.extend(training_sentences)\n",
    "\n",
    "#print training_data[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CRFTagger()\n",
    "ct.train(training_data,'model.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Five', 'O'), (u'people', 'O'), (u'were', 'O'), (u'killed', 'O'), (u'and', 'O'), (u'over', 'O'), (u'50', 'O'), (u'injured', 'O'), (u'in', 'O'), (u'three', 'O'), (u'blasts', 'O'), (u'set', 'O'), (u'off', 'O'), (u'by', 'O'), (u'insurgent', 'O'), (u'outfit', 'O'), (u'ULFA', 'ORG_Accused'), (u'here', 'O'), (u'today', 'O'), (u'hours', 'O'), (u'before', 'O'), (u'Union', 'O'), (u'Home', 'O'), (u'Minister', 'O'), (u'P', 'PER_Others'), (u'Chidambaram', 'PER_Others'), (u\"'s\", 'O'), (u'visit', 'O'), (u'to', 'O'), (u'review', 'O'), (u'law', 'O'), (u'and', 'O'), (u'order', 'O'), (u'situation', 'O'), (u'in', 'O'), (u'the', 'O'), (u'state', 'O'), (u'rocked', 'O'), (u'by', 'O'), (u'deadly', 'O'), (u'blasts', 'O'), (u'that', 'O'), (u'left', 'O'), (u'88', 'O'), (u'dead', 'O'), (u'two', 'O'), (u'months', 'O'), (u'ago', 'O'), (u'.', 'O'), (u'.', 'O'), (u'.', 'O'), (u'Three', 'O'), (u'people', 'O'), (u'were', 'O'), (u'killed', 'O'), (u'and', 'O'), (u'35', 'O'), (u'injured', 'O'), (u',', 'O'), (u'including', 'O'), (u'four', 'O'), (u'women', 'O'), (u',', 'O'), (u'when', 'O'), (u'a', 'O'), (u'bomb', 'O'), (u'planted', 'O'), (u'in', 'O'), (u'front', 'O'), (u'of', 'O'), (u'a', 'O'), (u'closed', 'O'), (u'sweet', 'O'), (u'shop', 'O'), (u'exploded', 'O'), (u'near', 'O'), (u'upmarket', 'O'), (u'Bhangagarh', 'LOC_Event'), (u'flyover', 'O'), (u'on', 'O'), (u'the', 'O'), (u'busy', 'O'), (u'Guwahati-Shillong', 'O'), (u'road', 'O'), (u'at', 'O'), (u'around', 'O'), (u'5:45', 'O'), (u'pm', 'O'), (u'.', 'O'), (u'.', 'O'), (u'.', 'O'), (u'Two', 'O'), (u'persons', 'O'), (u'died', 'O'), (u'on', 'O'), (u'way', 'O'), (u'to', 'O'), (u'hospital', 'O'), (u'while', 'O'), (u'another', 'O'), (u'succumbed', 'O'), (u'to', 'O'), (u'his', 'O'), (u'injuries', 'O'), (u'at', 'O'), (u'the', 'O'), (u'Guwahati', 'ORG_Others'), (u'Medical', 'ORG_Others'), (u'College', 'ORG_Others'), (u'Hospital', 'ORG_Others'), (u',', 'O'), (u'DGP', 'O'), (u'G', 'PER_Others'), (u'M', 'PER_Others'), (u'Srivastava', 'PER_Others'), (u'said', 'O'), (u'.', 'O'), (u'.', 'O'), (u'.', 'O'), (u'Two', 'O'), (u'of', 'O'), (u'the', 'O'), (u'dead', 'O'), (u'were', 'O'), (u'identified', 'O'), (u'as', 'O'), (u'Amal', 'PER_Victim'), (u'Das', 'PER_Victim'), (u'and', 'O'), (u'Kahil', 'PER_Others'), (u'Sheikh', 'PER_Others'), (u'.', 'O'), (u'.', 'O'), (u'.', 'O'), (u'A', 'O'), (u'bomb', 'O'), (u'kept', 'O'), (u'in', 'O'), (u'a', 'O'), (u'bicycle', 'O'), (u'exploded', 'O'), (u'at', 'O'), (u'a', 'O'), (u'market', 'O'), (u'in', 'O'), (u'the', 'O'), (u'Bhootnath', 'O'), (u'area', 'O'), (u',', 'O'), (u'the', 'O'), (u'route', 'O'), (u'which', 'O'), (u'Chidambaram', 'PER_Others'), (u'was', 'O'), (u'to', 'O'), (u'take', 'O'), (u'on', 'O'), (u'his', 'O'), (u'way', 'O'), (u'from', 'O'), (u'the', 'O'), (u'airport', 'O'), (u',', 'O'), (u'under', 'O'), (u'Baralumukh', 'ORG_Others'), (u'police', 'ORG_Others'), (u'station', 'ORG_Others'), (u'around', 'O'), (u'5.30', 'O'), (u'pm', 'O'), (u'in', 'O'), (u'which', 'O'), (u'two', 'O'), (u'persons', 'O'), (u'were', 'O'), (u'killed', 'O'), (u'and', 'O'), (u'12', 'O'), (u'others', 'O'), (u'injured', 'O'), (u',', 'O'), (u'official', 'O'), (u'sources', 'O'), (u'said', 'O'), (u'.', 'O'), (u'.', 'O'), (u'.', 'O'), (u'An', 'O'), (u'Improvised', 'O'), (u'Explosive', 'O'), (u'Devise', 'O'), (u'(', 'O'), (u'IED', 'O'), (u')', 'O'), (u'kept', 'O'), (u'in', 'O'), (u'a', 'O'), (u'Gauhati', 'ORG_Others'), (u'Municipal', 'ORG_Others'), (u'Corporation', 'ORG_Others'), (u'(', 'O'), (u'GMC', 'ORG_Others'), (u')', 'O'), (u'dustbin', 'O'), (u'went', 'O'), (u'off', 'O'), (u'at', 'O'), (u'around', 'O'), (u'3.30', 'O'), (u'pm', 'O'), (u'injuring', 'O'), (u'three', 'O'), (u'persons', 'O'), (u'in', 'O'), (u'Birubari', 'LOC_Event'), (u'Tiniali', 'LOC_Event'), (u'area', 'O'), (u'.', 'O'), (u'.', 'O'), (u'.', 'O'), (u'The', 'O'), (u'blasts', 'O'), (u'came', 'O'), (u'a', 'O'), (u'day', 'O'), (u'ahead', 'O'), (u'of', 'O'), (u'Prime', 'O'), (u'Minister', 'O'), (u'Manmohan', 'PER_Others'), (u'Singh', 'PER_Others'), (u\"'s\", 'O'), (u'arrival', 'O'), (u'here', 'O'), (u'tomorrow', 'O'), (u'enroute', 'O'), (u'Shillong', 'O'), (u'to', 'O'), (u'inaugurate', 'O'), (u'the', 'O'), (u'Indian', 'ORG_Others'), (u'Science', 'ORG_Others'), (u'Congress', 'ORG_Others'), (u'there', 'O'), (u'on', 'O'), (u'January', 'O'), (u'three', 'O'), (u'.', 'O'), (u'.', 'O'), (u'.', 'O'), (u'Chidmabaram', 'O'), (u'arrived', 'O'), (u'at', 'O'), (u'the', 'O'), (u'Lokopriyo', 'PER_Others'), (u'Gopinath', 'PER_Others'), (u'Bordoloi', 'PER_Others'), (u'international', 'O'), (u'airport', 'O'), (u'on', 'O'), (u'a', 'O'), (u'two-day', 'O'), (u'visit', 'O'), (u'to', 'O'), (u'the', 'O'), (u'state', 'O'), (u'to', 'O'), (u'review', 'O'), (u'Assam', 'LOC_Others'), (u\"'s\", 'O'), (u'law', 'O'), (u'and', 'O'), (u'order', 'O'), (u'situation', 'O'), (u'and', 'O'), (u'attend', 'O'), (u'a', 'O'), (u'meeting', 'O'), (u'of', 'O'), (u'the', 'O'), (u'Unified', 'O'), (u'Command', 'O'), (u'headed', 'O'), (u'by', 'O'), (u'Chief', 'O'), (u'Minister', 'O'), (u'Tarun', 'PER_Others'), (u'Gogoi', 'PER_Others'), (u'.', 'O'), (u'.', 'O'), (u'.', 'O'), (u'.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "for f in test_file_list:\n",
    "    word_file_path = os.path.join(doc_dir, f)\n",
    "    with io.open(word_file_path, \"rt\", encoding=\"utf-8\") as word_file:\n",
    "        for line in word_file:\n",
    "            predicted_tags = ct.tag_sents([line.split()])\n",
    "            print predicted_tags[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOC_Others': 1743, 'LOC_Accused': 120, 'ORG_Accused': 546, 'LOC_Victim': 27, 'PER_Others': 1702, 'ORG_Others': 2015, 'LOC_Event': 1100, 'PER_Victim': 268, 'ORG_Victim': 81, 'PER_Accused': 599}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "actual_tag_count = dict()\n",
    "matched_tag_count = dict()\n",
    "matched_tag_count[u'PER_Others'] = 0\n",
    "actual_tag_count[u'PER_Others'] = 0\n",
    "matched_tag_count[u'PER_Victim'] = 0\n",
    "actual_tag_count[u'PER_Victim'] = 0\n",
    "matched_tag_count[u'PER_Accused'] = 0\n",
    "actual_tag_count[u'PER_Accused'] = 0\n",
    "matched_tag_count[u'ORG_Victim'] = 0\n",
    "actual_tag_count[u'ORG_Victim'] = 0\n",
    "matched_tag_count[u'ORG_Accused'] = 0\n",
    "actual_tag_count[u'ORG_Accused'] = 0\n",
    "matched_tag_count[u'ORG_Others'] = 0\n",
    "actual_tag_count[u'ORG_Others'] = 0\n",
    "matched_tag_count[u'LOC_Accused'] = 0\n",
    "actual_tag_count[u'LOC_Accused'] = 0\n",
    "matched_tag_count[u'LOC_Others'] = 0\n",
    "actual_tag_count[u'LOC_Others'] = 0\n",
    "matched_tag_count[u'LOC_Event'] = 0\n",
    "actual_tag_count[u'LOC_Event'] = 0\n",
    "matched_tag_count[u'LOC_Victim'] = 0\n",
    "actual_tag_count[u'LOC_Victim'] = 0\n",
    "\n",
    "for f in test_file_list:\n",
    "    word_file_path = os.path.join(doc_dir, f)\n",
    "    tag_file_path = os.path.join(tag_dir, f)\n",
    "    predicted_tags = []\n",
    "    with io.open(word_file_path, \"rt\", encoding=\"utf-8\") as word_file:\n",
    "        for line in word_file:\n",
    "            predicted_tags = ct.tag_sents([line.split()])\n",
    "            #print predicted_tags\n",
    "    if len(predicted_tags) > 0 and len(predicted_tags[0]) > 0:\n",
    "        actual_tags = []\n",
    "        with io.open(tag_file_path, \"rt\", encoding=\"utf-8\") as tag_file:\n",
    "            for line in tag_file:\n",
    "                #print(line + '\\n')\n",
    "                actual_tags = line.split()\n",
    "                #print actual_tags\n",
    "        result_len = min(len(predicted_tags[0]), len(actual_tags))\n",
    "        \n",
    "        for i in range(result_len):\n",
    "            #print predicted_tags[i][1], actual_tags[i]\n",
    "            if actual_tags[i] in actual_tag_count.keys():\n",
    "                actual_tag_count[actual_tags[i]] = actual_tag_count[actual_tags[i]] + 1\n",
    "                \n",
    "            if actual_tags[i] == predicted_tags[0][i][1]:\n",
    "                if actual_tags[i] in matched_tag_count.keys():\n",
    "                    matched_tag_count[actual_tags[i]] = matched_tag_count[actual_tags[i]] + 1\n",
    "\n",
    "print(actual_tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Accuracy Class Wise =====================\n",
      "\n",
      "Class    Matched Total %\n",
      "--------------------------\n",
      "PER_Others: 1257 1702 73.85428907168037%\n",
      "PER_Victim: 28 268 10.447761194029852%\n",
      "PER_Accused: 205 599 34.223706176961606%\n",
      "ORG_Victim: 0 81 0.0%\n",
      "ORG_Accused: 379 546 69.41391941391942%\n",
      "ORG_Others: 1289 2015 63.97022332506204%\n",
      "LOC_Accused: 0 120 0.0%\n",
      "LOC_Others: 961 1743 55.134825014343086%\n",
      "LOC_Event: 475 1100 43.18181818181818%\n",
      "LOC_Victim: 0 27 0.0%\n"
     ]
    }
   ],
   "source": [
    "print('======= Accuracy Class Wise =====================\\n')\n",
    "\n",
    "print('Class    Matched Total %')\n",
    "print('--------------------------')\n",
    "print ('PER_Others: '+str(matched_tag_count['PER_Others'])+ ' ' + str(actual_tag_count['PER_Others'])+ ' ' + str(matched_tag_count['PER_Others']*100/actual_tag_count['PER_Others'])+'%')\n",
    "print ('PER_Victim: '+str(matched_tag_count['PER_Victim'])+ ' ' + str(actual_tag_count['PER_Victim'])+ ' '+str(matched_tag_count['PER_Victim']*100/actual_tag_count['PER_Victim'])+'%')\n",
    "print ('PER_Accused: '+str(matched_tag_count['PER_Accused'])+ ' ' + str(actual_tag_count['PER_Accused'])+ ' '+str(matched_tag_count['PER_Accused']*100/actual_tag_count['PER_Accused'])+'%')\n",
    "print ('ORG_Victim: '+str(matched_tag_count['ORG_Victim']) + ' '+ str(actual_tag_count['ORG_Victim'])+ ' '+str(matched_tag_count['ORG_Victim']*100/actual_tag_count['ORG_Victim'])+'%')\n",
    "print ('ORG_Accused: '+str(matched_tag_count['ORG_Accused']) + ' '+ str(actual_tag_count['ORG_Accused'])+ ' '+str(matched_tag_count['ORG_Accused']*100/actual_tag_count['ORG_Accused'])+'%')\n",
    "print ('ORG_Others: '+str(matched_tag_count['ORG_Others']) + ' '+ str(actual_tag_count['ORG_Others'])+ ' '+str(matched_tag_count['ORG_Others']*100/actual_tag_count['ORG_Others'])+'%')\n",
    "print ('LOC_Accused: '+str(matched_tag_count['LOC_Accused'])+ ' ' + str(actual_tag_count['LOC_Accused'])+ ' '+str(matched_tag_count['LOC_Accused']*100/actual_tag_count['LOC_Accused'])+'%')\n",
    "print ('LOC_Others: '+str(matched_tag_count['LOC_Others'])+ ' ' + str(actual_tag_count['LOC_Others'])+ ' '+str(matched_tag_count['LOC_Others']*100/actual_tag_count['LOC_Others'])+'%')\n",
    "print ('LOC_Event: '+str(matched_tag_count['LOC_Event']) + ' '+ str(actual_tag_count['LOC_Event'])+ ' '+str(matched_tag_count['LOC_Event']*100/actual_tag_count['LOC_Event'])+'%')\n",
    "print ('LOC_Victim: '+str(matched_tag_count['LOC_Victim']) + ' '+ str(actual_tag_count['LOC_Victim'])+ ' '+str(matched_tag_count['LOC_Victim']*100/actual_tag_count['LOC_Victim'])+'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
