{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import CRFTagger\n",
    "import os\n",
    "import numpy as np\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035\n",
      "272\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset for NLTK HMM Tagger\n",
    "# Divide in train and test files [80:20] \n",
    "\n",
    "# Directory having content\n",
    "doc_dir = 'Data/content'\n",
    "\n",
    "train_file_list = []\n",
    "test_file_list = []\n",
    "\n",
    "for f in os.listdir(doc_dir):\n",
    "    #Random Sampling\n",
    "    if np.random.uniform(0,1)< 0.8:\n",
    "        train_file_list.append(f)\n",
    "    else:\n",
    "        test_file_list.append(f)\n",
    "\n",
    "print len(train_file_list)\n",
    "print len(test_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Tagged dataset to be fed in nltk hmm tagger\n",
    "# It is a list of tagged sentences. \n",
    "# training_data = [ [(word, tag), (word, tag).....]\n",
    "# [(word, tag), (word, tag).....]\n",
    "#]\n",
    "\n",
    "# Directory having tags\n",
    "tag_dir = 'Data/new_tags'\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for f in train_file_list:\n",
    "    training_sentences =[]\n",
    "    word_file_path = os.path.join(doc_dir, f)\n",
    "    tag_file_path = os.path.join(tag_dir, f)\n",
    "    lines_in_word_file = []\n",
    "    lines_in_tag_file = []\n",
    "    with io.open(word_file_path, \"rt\", encoding=\"utf-8\") as word_file:\n",
    "        for line in word_file:\n",
    "            lines_in_word_file.append(line)\n",
    "    with io.open(tag_file_path, \"rt\", encoding=\"utf-8\") as tag_file:\n",
    "        for line in tag_file:\n",
    "            lines_in_tag_file.append(line)\n",
    "    if (len(lines_in_word_file) == len(lines_in_tag_file)) and len(lines_in_word_file) > 0:\n",
    "        for i in xrange(len(lines_in_word_file)):\n",
    "            word_in_file = lines_in_word_file[i].split()\n",
    "            tag_in_file = lines_in_tag_file[i].split()\n",
    "            pairs_in_line = []\n",
    "            length = min(len(word_in_file), len(tag_in_file))\n",
    "            #Create the word_tag pair\n",
    "            for j in xrange(length):\n",
    "                pairs_in_line.append((word_in_file[j], tag_in_file[j]));\n",
    "            training_sentences.append(pairs_in_line)\n",
    "    if len(training_sentences) > 0:\n",
    "        training_data.extend(training_sentences)\n",
    "\n",
    "#print training_data[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CRFTagger()\n",
    "ct.train(training_data,'model.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Atiq', 'PER_Others'), (u'Khan', 'PER_Others'), (u'.', 'O'), (u'.', 'O'), (u'LUCKNOW', 'LOC_Others'), (u':', 'O'), (u'The', 'O'), (u'Anti-Terrorism', 'ORG_Others'), (u'Squad', 'ORG_Others'), (u'-LRB-', 'O'), (u'ATS', 'O'), (u'-RRB-', 'O'), (u',', 'O'), (u'Mumbai', 'LOC_Others'), (u',', 'O'), (u'on', 'O'), (u'Thursday', 'O'), (u'secured', 'O'), (u'the', 'O'), (u'transit', 'O'), (u'remand', 'O'), (u'for', 'O'), (u'Sudhakar', 'PER_Others'), (u'Dwivedi', 'PER_Others'), (u',', 'O'), (u'alias', 'O'), (u'Amritanand', 'O'), (u',', 'O'), (u'a', 'O'), (u'suspect', 'O'), (u'in', 'O'), (u'the', 'O'), (u'Malegaon', 'LOC_Event'), (u'bomb', 'O'), (u'blast', 'O'), (u'case', 'O'), (u'of', 'O'), (u'September', 'O'), (u',', 'O'), (u'2008', 'O'), (u'.', 'O'), (u'The', 'O'), (u'remand', 'O'), (u'till', 'O'), (u'November', 'O'), (u'16', 'O'), (u'was', 'O'), (u'granted', 'O'), (u'by', 'O'), (u'Mukesh', 'PER_Others'), (u'Kumar', 'PER_Others'), (u',', 'O'), (u'Civil', 'O'), (u'Judge', 'O'), (u',', 'O'), (u'Junior', 'O'), (u'Division', 'O'), (u',', 'O'), (u'Lucknow', 'LOC_Others'), (u'.', 'O'), (u'.', 'O'), (u'.', 'O'), (u'His', 'O'), (u'name', 'O'), (u'had', 'O'), (u'earlier', 'O'), (u'been', 'O'), (u'disclosed', 'O'), (u'as', 'O'), (u'Dayanand', 'PER_Accused'), (u'Pandey', 'PER_Accused'), (u'but', 'O'), (u',', 'O'), (u'following', 'O'), (u'calls', 'O'), (u'from', 'O'), (u'the', 'O'), (u'DGPs', 'O'), (u'office', 'O'), (u'late', 'O'), (u'on', 'O'), (u'Wednesday', 'O'), (u'night', 'O'), (u',', 'O'), (u'it', 'O'), (u'was', 'O'), (u'given', 'O'), (u'as', 'O'), (u'Sudhakar', 'PER_Others'), (u'Dwivedi', 'PER_Others'), (u',', 'O'), (u'son', 'O'), (u'of', 'O'), (u'Dayanand', 'PER_Others'), (u'Dwivedi', 'PER_Others'), (u'.', 'O'), (u'He', 'O'), (u'had', 'O'), (u'taken', 'O'), (u'the', 'O'), (u'name', 'O'), (u'Amritanand', 'O'), (u'and', 'O'), (u'become', 'O'), (u'the', 'O'), (u'Peethadheeshwar', 'O'), (u'of', 'O'), (u'the', 'O'), (u'Sharda', 'PER_Others'), (u'Sarvagya', 'PER_Others'), (u'Peeth', 'PER_Others'), (u'in', 'O'), (u'Jammu', 'LOC_Others'), (u'.', 'O'), (u'.', 'O'), (u'.', 'O'), (u'Dwivedi', 'O'), (u'was', 'O'), (u'picked', 'O'), (u'up', 'O'), (u'by', 'O'), (u'the', 'O'), (u'Mumbai', 'ORG_Others'), (u'ATS', 'ORG_Others'), (u'from', 'O'), (u'the', 'O'), (u'residence', 'O'), (u'of', 'O'), (u'his', 'O'), (u'brother', 'O'), (u',', 'O'), (u'Pushkar', 'PER_Others'), (u'Dwivedi', 'PER_Others'), (u',', 'O'), (u'at', 'O'), (u'Rawatpur', 'LOC_Others'), (u'village', 'O'), (u'in', 'O'), (u'Kanpur', 'LOC_Others'), (u'on', 'O'), (u'Wednesday', 'O'), (u'.', 'O'), (u'He', 'O'), (u'is', 'O'), (u'to', 'O'), (u'be', 'O'), (u'taken', 'O'), (u'to', 'O'), (u'Mumbai', 'LOC_Others'), (u'for', 'O'), (u'further', 'O'), (u'interrogation', 'O'), (u'.', 'O'), (u'.', 'O'), (u'.', 'O'), (u'Dwivedi', 'O'), (u'was', 'O'), (u'brought', 'O'), (u'to', 'O'), (u'Lucknow', 'LOC_Others'), (u'on', 'O'), (u'Wednesday', 'O'), (u'night', 'O'), (u'and', 'O'), (u'was', 'O'), (u'subjected', 'O'), (u'to', 'O'), (u'a', 'O'), (u'detailed', 'O'), (u'interrogation', 'O'), (u'.', 'O'), (u'Details', 'O'), (u'of', 'O'), (u'the', 'O'), (u'closed-door', 'O'), (u'interrogation', 'O'), (u'were', 'O'), (u'not', 'O'), (u'known', 'O'), (u',', 'O'), (u'but', 'O'), (u'sources', 'O'), (u'said', 'O'), (u'the', 'O'), (u'ATS', 'O'), (u'was', 'O'), (u'looking', 'O'), (u'into', 'O'), (u'his', 'O'), (u'contacts', 'O'), (u'with', 'O'), (u'some', 'O'), (u'Hindu', 'O'), (u'organisation', 'O'), (u'leaders', 'O'), (u'of', 'O'), (u'Central', 'LOC_Event'), (u'Uttar', 'LOC_Event'), (u'Pradesh', 'LOC_Event'), (u'.', 'O'), (u'His', 'O'), (u'name', 'O'), (u'surfaced', 'O'), (u'after', 'O'), (u'the', 'O'), (u'ATS', 'O'), (u'team', 'O'), (u',', 'O'), (u'conducting', 'O'), (u'the', 'O'), (u'investigation', 'O'), (u'into', 'O'), (u'the', 'O'), (u'Malegaon', 'LOC_Event'), (u'blasts', 'O'), (u'and', 'O'), (u'the', 'O'), (u'alleged', 'O'), (u'involvement', 'O'), (u'of', 'O'), (u'a', 'O'), (u'retired', 'O'), (u'Lieutenant-Colonel', 'O'), (u',', 'O'), (u'found', 'O'), (u'that', 'O'), (u'he', 'O'), (u'was', 'O'), (u'in', 'O'), (u'touch', 'O'), (u'with', 'O'), (u'Sadhvi', 'PER_Others'), (u'Pragnya', 'PER_Others'), (u'Singh', 'PER_Others'), (u',', 'O'), (u'another', 'O'), (u'accused', 'O'), (u'in', 'O'), (u'the', 'O'), (u'case', 'O'), (u',', 'O'), (u'the', 'O'), (u'sources', 'O'), (u'said', 'O'), (u'.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "for f in test_file_list:\n",
    "    word_file_path = os.path.join(doc_dir, f)\n",
    "    with io.open(word_file_path, \"rt\", encoding=\"utf-8\") as word_file:\n",
    "        for line in word_file:\n",
    "            predicted_tags = ct.tag_sents([line.split()])\n",
    "            print predicted_tags[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'PER_Others': 1970, u'LOC_Event': 1467, u'LOC_Others': 1822, u'ORG_Accused': 605, u'PER_Victim': 256, u'ORG_Victim': 69, u'ORG_Others': 2510, u'PER_Accused': 947, u'LOC_Accused': 173, u'LOC_Victim': 34}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "actual_tag_count = dict()\n",
    "matched_tag_count = dict()\n",
    "matched_tag_count[u'PER_Others'] = 0\n",
    "actual_tag_count[u'PER_Others'] = 0\n",
    "matched_tag_count[u'PER_Victim'] = 0\n",
    "actual_tag_count[u'PER_Victim'] = 0\n",
    "matched_tag_count[u'PER_Accused'] = 0\n",
    "actual_tag_count[u'PER_Accused'] = 0\n",
    "matched_tag_count[u'ORG_Victim'] = 0\n",
    "actual_tag_count[u'ORG_Victim'] = 0\n",
    "matched_tag_count[u'ORG_Accused'] = 0\n",
    "actual_tag_count[u'ORG_Accused'] = 0\n",
    "matched_tag_count[u'ORG_Others'] = 0\n",
    "actual_tag_count[u'ORG_Others'] = 0\n",
    "matched_tag_count[u'LOC_Accused'] = 0\n",
    "actual_tag_count[u'LOC_Accused'] = 0\n",
    "matched_tag_count[u'LOC_Others'] = 0\n",
    "actual_tag_count[u'LOC_Others'] = 0\n",
    "matched_tag_count[u'LOC_Event'] = 0\n",
    "actual_tag_count[u'LOC_Event'] = 0\n",
    "matched_tag_count[u'LOC_Victim'] = 0\n",
    "actual_tag_count[u'LOC_Victim'] = 0\n",
    "\n",
    "for f in test_file_list:\n",
    "    word_file_path = os.path.join(doc_dir, f)\n",
    "    tag_file_path = os.path.join(tag_dir, f)\n",
    "    predicted_tags = []\n",
    "    with io.open(word_file_path, \"rt\", encoding=\"utf-8\") as word_file:\n",
    "        for line in word_file:\n",
    "            predicted_tags = ct.tag_sents([line.split()])\n",
    "    if len(predicted_tags[0]) > 0:\n",
    "        actual_tags = []\n",
    "        with io.open(tag_file_path, \"rt\", encoding=\"utf-8\") as tag_file:\n",
    "            for line in tag_file:\n",
    "                #print(line + '\\n')\n",
    "                actual_tags = line.split()\n",
    "                #print actual_tags\n",
    "        result_len = min(len(predicted_tags[0]), len(actual_tags))\n",
    "        \n",
    "        for i in xrange(result_len):\n",
    "            #print predicted_tags[i][1], actual_tags[i]\n",
    "            if actual_tags[i] in actual_tag_count.keys():\n",
    "                actual_tag_count[actual_tags[i]] = actual_tag_count[actual_tags[i]] + 1\n",
    "                \n",
    "            if actual_tags[i] == predicted_tags[0][i][1]:\n",
    "                if actual_tags[i] in matched_tag_count.keys():\n",
    "                    matched_tag_count[actual_tags[i]] = matched_tag_count[actual_tags[i]] + 1\n",
    "\n",
    "print actual_tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Accuracy Class Wise =====================\n",
      "\n",
      "Class    Matched Total %\n",
      "--------------------------\n",
      "PER_Others: 1407 1970 71%\n",
      "PER_Victim: 8 256 3%\n",
      "PER_Accused: 293 947 30%\n",
      "ORG_Victim: 0 69 0%\n",
      "ORG_Accused: 461 605 76%\n",
      "ORG_Others: 1257 2510 50%\n",
      "LOC_Accused: 0 173 0%\n",
      "LOC_Others: 971 1822 53%\n",
      "LOC_Event: 622 1467 42%\n",
      "LOC_Victim: 0 34 0%\n"
     ]
    }
   ],
   "source": [
    "print('======= Accuracy Class Wise =====================\\n')\n",
    "\n",
    "print('Class    Matched Total %')\n",
    "print('--------------------------')\n",
    "print ('PER_Others: '+str(matched_tag_count['PER_Others'])+ ' ' + str(actual_tag_count['PER_Others'])+ ' ' + str(matched_tag_count['PER_Others']*100/actual_tag_count['PER_Others'])+'%')\n",
    "print ('PER_Victim: '+str(matched_tag_count['PER_Victim'])+ ' ' + str(actual_tag_count['PER_Victim'])+ ' '+str(matched_tag_count['PER_Victim']*100/actual_tag_count['PER_Victim'])+'%')\n",
    "print ('PER_Accused: '+str(matched_tag_count['PER_Accused'])+ ' ' + str(actual_tag_count['PER_Accused'])+ ' '+str(matched_tag_count['PER_Accused']*100/actual_tag_count['PER_Accused'])+'%')\n",
    "print ('ORG_Victim: '+str(matched_tag_count['ORG_Victim']) + ' '+ str(actual_tag_count['ORG_Victim'])+ ' '+str(matched_tag_count['ORG_Victim']*100/actual_tag_count['ORG_Victim'])+'%')\n",
    "print ('ORG_Accused: '+str(matched_tag_count['ORG_Accused']) + ' '+ str(actual_tag_count['ORG_Accused'])+ ' '+str(matched_tag_count['ORG_Accused']*100/actual_tag_count['ORG_Accused'])+'%')\n",
    "print ('ORG_Others: '+str(matched_tag_count['ORG_Others']) + ' '+ str(actual_tag_count['ORG_Others'])+ ' '+str(matched_tag_count['ORG_Others']*100/actual_tag_count['ORG_Others'])+'%')\n",
    "print ('LOC_Accused: '+str(matched_tag_count['LOC_Accused'])+ ' ' + str(actual_tag_count['LOC_Accused'])+ ' '+str(matched_tag_count['LOC_Accused']*100/actual_tag_count['LOC_Accused'])+'%')\n",
    "print ('LOC_Others: '+str(matched_tag_count['LOC_Others'])+ ' ' + str(actual_tag_count['LOC_Others'])+ ' '+str(matched_tag_count['LOC_Others']*100/actual_tag_count['LOC_Others'])+'%')\n",
    "print ('LOC_Event: '+str(matched_tag_count['LOC_Event']) + ' '+ str(actual_tag_count['LOC_Event'])+ ' '+str(matched_tag_count['LOC_Event']*100/actual_tag_count['LOC_Event'])+'%')\n",
    "print ('LOC_Victim: '+str(matched_tag_count['LOC_Victim']) + ' '+ str(actual_tag_count['LOC_Victim'])+ ' '+str(matched_tag_count['LOC_Victim']*100/actual_tag_count['LOC_Victim'])+'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
