{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import anago\n",
    "from anago.data.reader import load_data_and_labels, load_word_embeddings\n",
    "from anago.data.preprocess import prepare_preprocessor\n",
    "from anago.config import ModelConfig, TrainingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_ROOT = 'data/conll2003/en/ner'\n",
    "DATA_ROOT = 'data/osint/blast'\n",
    "SAVE_ROOT = 'models'  # trained model\n",
    "LOG_ROOT = './logs'     # checkpoint, tensorboard\n",
    "embedding_path = 'data/glove.6B/glove.6B.100d.txt'\n",
    "model_config = ModelConfig()\n",
    "training_config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(DATA_ROOT, 'train.txt')\n",
    "valid_path = os.path.join(DATA_ROOT, 'valid.txt')\n",
    "test_path = os.path.join(DATA_ROOT, 'test.txt')\n",
    "x_train, y_train = load_data_and_labels(train_path)\n",
    "x_valid, y_valid = load_data_and_labels(valid_path)\n",
    "x_test, y_test = load_data_and_labels(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = prepare_preprocessor(x_train, y_train)\n",
    "embeddings = load_word_embeddings(p.vocab_word, embedding_path, model_config.word_embedding_size)\n",
    "model_config.vocab_size = len(p.vocab_word)\n",
    "model_config.char_vocab_size = len(p.vocab_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1166/1167 [============================>.] - ETA: 0s - loss: 115.0450 - f1: 0.00\n",
      "1167/1167 [==============================] - 692s - loss: 115.0687   \n"
     ]
    }
   ],
   "source": [
    "trainer = anago.Trainer(model_config, training_config, checkpoint_path=LOG_ROOT, save_path=SAVE_ROOT,\n",
    "                        preprocessor=p, embeddings=embeddings)\n",
    "trainer.train(x_train, y_train, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "batch_iter() takes at least 3 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-fce2958630c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSAVE_ROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/neelesh/GitRespository/GitHub/MTP/EntityRoleLabelling/Experiments/Methods/LSTM/Help/anago/anago/evaluator.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, x_test, y_test)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Prepare test data(steps, generator)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         train_steps, train_batches = batch_iter(\n\u001b[0;32m---> 25\u001b[0;31m             list(zip(x_test, y_test)), self.config.batch_size, preprocessor=self.preprocessor)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Build the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: batch_iter() takes at least 3 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "weights = 'model_weights.h5'\n",
    "\n",
    "evaluator = anago.Evaluator(model_config, weights, save_path=SAVE_ROOT, preprocessor=p)\n",
    "evaluator.eval(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 'model_weights.h5'\n",
    "tagger = anago.Tagger(model_config, weights, save_path=SAVE_ROOT, preprocessor=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('President', 'O'), ('Obama', 'PER_Others'), ('is', 'O'), ('speaking', 'O'), ('at', 'O'), ('the', 'O'), ('White', 'O'), ('House.', 'ORG_Others')]\n"
     ]
    }
   ],
   "source": [
    "sent = 'President Obama is speaking at the White House.'\n",
    "print(tagger.tag(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(x_test[0])\\nstr1 = ' '.join(x_test[0])\\nprint str1\\ntagged = tagger.tag(str1)\\nprint tagged[0][1]\\nprint(y_test[0][0])\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "actual_tag_count = dict()\n",
    "matched_tag_count = dict()\n",
    "matched_tag_count['PER_Others'] = 0\n",
    "actual_tag_count['PER_Others'] = 0\n",
    "matched_tag_count['PER_Victim'] = 0\n",
    "actual_tag_count['PER_Victim'] = 0\n",
    "matched_tag_count['PER_Accused'] = 0\n",
    "actual_tag_count['PER_Accused'] = 0\n",
    "matched_tag_count['ORG_Victim'] = 0\n",
    "actual_tag_count['ORG_Victim'] = 0\n",
    "matched_tag_count['ORG_Accused'] = 0\n",
    "actual_tag_count['ORG_Accused'] = 0\n",
    "matched_tag_count['ORG_Others'] = 0\n",
    "actual_tag_count['ORG_Others'] = 0\n",
    "matched_tag_count['LOC_Accused'] = 0\n",
    "actual_tag_count['LOC_Accused'] = 0\n",
    "matched_tag_count['LOC_Others'] = 0\n",
    "actual_tag_count['LOC_Others'] = 0\n",
    "matched_tag_count['LOC_Event'] = 0\n",
    "actual_tag_count['LOC_Event'] = 0\n",
    "matched_tag_count['LOC_Victim'] = 0\n",
    "actual_tag_count['LOC_Victim'] = 0\n",
    "\n",
    "test_len = len(x_test)\n",
    "\n",
    "for i in xrange(test_len):\n",
    "    try:\n",
    "        teststr='';\n",
    "        tagged = []\n",
    "        teststr = ' '.join(x_test[i])\n",
    "        tagged = tagger.tag(teststr)\n",
    "        len_ = len(x_test[i])\n",
    "        for j in xrange(len_):\n",
    "            if y_test[i][j] in actual_tag_count.keys():\n",
    "                actual_tag_count[y_test[i][j]] = actual_tag_count[y_test[i][j]] + 1\n",
    "            if y_test[i][j] == tagged[j][1]:\n",
    "                if y_test[i][j] in matched_tag_count.keys():\n",
    "                    matched_tag_count[y_test[i][j]] = matched_tag_count[y_test[i][j]] + 1\n",
    "    except:\n",
    "        teststr = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Accuracy Class Wise =====================\n",
      "\n",
      "Class    Matched Total %\n",
      "--------------------------\n",
      "PER_Others: 650 828 78%\n",
      "PER_Victim: 2 107 1%\n",
      "PER_Accused: 196 393 49%\n",
      "ORG_Victim: 0 32 0%\n",
      "ORG_Accused: 179 270 66%\n",
      "ORG_Others: 568 1078 52%\n",
      "LOC_Accused: 0 128 0%\n",
      "LOC_Others: 461 890 51%\n",
      "LOC_Event: 418 692 60%\n",
      "LOC_Victim: 0 28 0%\n"
     ]
    }
   ],
   "source": [
    "print('======= Accuracy Class Wise =====================\\n')\n",
    "\n",
    "print('Class    Matched Total %')\n",
    "print('--------------------------')\n",
    "print ('PER_Others: '+str(matched_tag_count['PER_Others'])+ ' ' + str(actual_tag_count['PER_Others'])+ ' ' + str(matched_tag_count['PER_Others']*100/actual_tag_count['PER_Others'])+'%')\n",
    "print ('PER_Victim: '+str(matched_tag_count['PER_Victim'])+ ' ' + str(actual_tag_count['PER_Victim'])+ ' '+str(matched_tag_count['PER_Victim']*100/actual_tag_count['PER_Victim'])+'%')\n",
    "print ('PER_Accused: '+str(matched_tag_count['PER_Accused'])+ ' ' + str(actual_tag_count['PER_Accused'])+ ' '+str(matched_tag_count['PER_Accused']*100/actual_tag_count['PER_Accused'])+'%')\n",
    "print ('ORG_Victim: '+str(matched_tag_count['ORG_Victim']) + ' '+ str(actual_tag_count['ORG_Victim'])+ ' '+str(matched_tag_count['ORG_Victim']*100/actual_tag_count['ORG_Victim'])+'%')\n",
    "print ('ORG_Accused: '+str(matched_tag_count['ORG_Accused']) + ' '+ str(actual_tag_count['ORG_Accused'])+ ' '+str(matched_tag_count['ORG_Accused']*100/actual_tag_count['ORG_Accused'])+'%')\n",
    "print ('ORG_Others: '+str(matched_tag_count['ORG_Others']) + ' '+ str(actual_tag_count['ORG_Others'])+ ' '+str(matched_tag_count['ORG_Others']*100/actual_tag_count['ORG_Others'])+'%')\n",
    "print ('LOC_Accused: '+str(matched_tag_count['LOC_Accused'])+ ' ' + str(actual_tag_count['LOC_Accused'])+ ' '+str(matched_tag_count['LOC_Accused']*100/actual_tag_count['LOC_Accused'])+'%')\n",
    "print ('LOC_Others: '+str(matched_tag_count['LOC_Others'])+ ' ' + str(actual_tag_count['LOC_Others'])+ ' '+str(matched_tag_count['LOC_Others']*100/actual_tag_count['LOC_Others'])+'%')\n",
    "print ('LOC_Event: '+str(matched_tag_count['LOC_Event']) + ' '+ str(actual_tag_count['LOC_Event'])+ ' '+str(matched_tag_count['LOC_Event']*100/actual_tag_count['LOC_Event'])+'%')\n",
    "print ('LOC_Victim: '+str(matched_tag_count['LOC_Victim']) + ' '+ str(actual_tag_count['LOC_Victim'])+ ' '+str(matched_tag_count['LOC_Victim']*100/actual_tag_count['LOC_Victim'])+'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
